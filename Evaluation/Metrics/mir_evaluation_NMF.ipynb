{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSVSBh0xBDIC",
        "outputId": "bfc82734-d8fe-4045-e3e6-a6a525085ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval) (0.18.3)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi, mir_eval\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=c5792fb09c46208ac62c6eba08e4b86905d26da520e696d151a574d72c7c08e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100704 sha256=8bd77c1cdb18c4923fff0ad7d72df2ad7a2640f11dab647a174d83d4dfc4fd62\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n",
            "Successfully built pretty_midi mir_eval\n",
            "Installing collected packages: packaging, mir_eval, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed mido-1.3.2 mir_eval-0.7 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi mir_eval numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK9FpIshBIWY",
        "outputId": "80a638c1-c1b4-4748-c021-648020d3eb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pretty_midi\n",
        "import mir_eval\n",
        "import numpy as np\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code\")\n",
        "\n",
        "def read_note_data_from_text(file_path):\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            start, end, pitch = line.strip().split()\n",
        "            intervals.append([float(start), float(end)])\n",
        "            pitches.append(int(pitch))\n",
        "    # print(np.array(intervals))\n",
        "    return np.array(intervals), np.array(pitches)\n",
        "\n",
        "# def read_note_data_from_text(file_path): # For OMAPS2\n",
        "#     intervals = []\n",
        "#     pitches = []\n",
        "#     velocities = []\n",
        "#     with open(file_path, 'r') as file:\n",
        "#         for line in file:\n",
        "#             columns = line.strip().split()\n",
        "#             start, end, pitch, velocity = columns\n",
        "#             intervals.append([float(start), float(end)])\n",
        "#             pitches.append(int(pitch))\n",
        "#             velocities.append(int(velocity))\n",
        "#     return np.array(intervals), np.array(pitches)\n",
        "\n",
        "# def prepare_data_for_evaluation(midi_file, cc_list=[64, 67], split_pedal=False):\n",
        "#     midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "#     notes = []\n",
        "#     for instrument in midi_data.instruments:\n",
        "#         if instrument.program in range(0, 8):\n",
        "#             notes.extend(instrument.notes)\n",
        "\n",
        "#     intervals = []\n",
        "#     pitches = []\n",
        "#     velocities = []\n",
        "#     for note in notes:\n",
        "#         if note.pitch >= 0 or -note.pitch in cc_list:\n",
        "#             intervals.append([note.start, note.end])\n",
        "#             pitches.append(midi_to_freq(note.pitch))\n",
        "#             velocities.append(note.velocity)\n",
        "\n",
        "#     intervals = np.array(intervals)\n",
        "#     pitches = np.array(pitches)\n",
        "#     velocities = np.array(velocities)\n",
        "\n",
        "#     return intervals, pitches, velocities\n",
        "\n",
        "# def evaluate_midi(predicted_midi_file, truth_midi_file):\n",
        "#     predicted_intervals, predicted_pitches, _ = prepare_data_for_evaluation(predicted_midi_file)\n",
        "#     truth_intervals, truth_pitches, _ = prepare_data_for_evaluation(truth_midi_file)\n",
        "\n",
        "#     precision, recall, f1_score, _ = mir_eval.transcription.precision_recall_f1_overlap(\n",
        "#         truth_intervals, truth_pitches, predicted_intervals, predicted_pitches)\n",
        "\n",
        "#     return precision, recall, f1_score\n",
        "\n",
        "def prepare_data_for_evaluation(midi_file):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    for instrument in midi_data.instruments:\n",
        "        for note in instrument.notes:\n",
        "            intervals.append([note.start, note.end])\n",
        "            pitches.append(note.pitch)\n",
        "    # print(np.array(intervals))\n",
        "    return np.array(intervals), np.array(pitches)\n",
        "\n",
        "def read_note_data_from_npy(file_path):\n",
        "    data = np.load(file_path)\n",
        "\n",
        "    intervals = data[:, :2]\n",
        "    pitches = data[:, 2]\n",
        "\n",
        "    return intervals, pitches\n",
        "\n",
        "def evaluate_midi(predicted_midi_file, truth_midi_file):\n",
        "    predicted_intervals, predicted_pitches = read_note_data_from_npy(predicted_midi_file)\n",
        "    truth_intervals, truth_pitches = read_note_data_from_text(truth_midi_file)\n",
        "\n",
        "    print(\"done\")\n",
        "\n",
        "    # Full evaluation considering only onset\n",
        "    full_precision, full_recall, full_f1_score, _ = mir_eval.transcription.precision_recall_f1_overlap(\n",
        "        truth_intervals, truth_pitches, predicted_intervals, predicted_pitches,\n",
        "        onset_tolerance=0.05, pitch_tolerance=50.0, offset_ratio=None, offset_min_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    # Onset evaluation\n",
        "    onset_precision, onset_recall, onset_f1_score = mir_eval.transcription.onset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, onset_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    # Offset evaluation\n",
        "    offset_precision, offset_recall, offset_f1_score = mir_eval.transcription.offset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, offset_ratio=0.2, offset_min_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    return {\n",
        "        'full': (full_precision, full_recall, full_f1_score),\n",
        "        'onset': (onset_precision, onset_recall, onset_f1_score),\n",
        "        'offset': (offset_precision, offset_recall, offset_f1_score)\n",
        "    }\n",
        "\n",
        "def evaluate_folders(predicted_folder, truth_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    full_eval_path = os.path.join(output_folder, \"full_evaluation_results.txt\")\n",
        "    onset_eval_path = os.path.join(output_folder, \"onset_evaluation_results.txt\")\n",
        "    offset_eval_path = os.path.join(output_folder, \"offset_evaluation_results.txt\")\n",
        "    full_avg_path = os.path.join(output_folder, \"full_evaluation_average.txt\")\n",
        "    onset_avg_path = os.path.join(output_folder, \"onset_evaluation_average.txt\")\n",
        "    offset_avg_path = os.path.join(output_folder, \"offset_evaluation_average.txt\")\n",
        "\n",
        "    full_scores = []\n",
        "    onset_scores = []\n",
        "    offset_scores = []\n",
        "\n",
        "    # Open the files outside the loop to write headers\n",
        "    with open(full_eval_path, 'w') as full_file, open(onset_eval_path, 'w') as onset_file, open(offset_eval_path, 'w') as offset_file:\n",
        "        full_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "        onset_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "        offset_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "\n",
        "    for predicted_file in os.listdir(predicted_folder):\n",
        "        if not predicted_file.endswith('.npy'):\n",
        "            # print(predicted_file)\n",
        "            continue  # Skip files that are not MIDI files\n",
        "\n",
        "        if predicted_file.endswith('-transcription.npy'):\n",
        "            # print(predicted_file)\n",
        "            predicted_path = os.path.join(predicted_folder, predicted_file)\n",
        "            truth_file = predicted_file.replace('-transcription.npy', '.txt')\n",
        "            truth_path = os.path.join(truth_folder, truth_file)\n",
        "\n",
        "        # print(truth_path, predicted_path)\n",
        "\n",
        "        if os.path.isfile(truth_path):\n",
        "            try:\n",
        "                results = evaluate_midi(predicted_path, truth_path)\n",
        "\n",
        "                # Append scores for averages calculation\n",
        "                full_scores.append(results['full'])\n",
        "                onset_scores.append(results['onset'])\n",
        "                offset_scores.append(results['offset'])\n",
        "\n",
        "                # Write detailed evaluation results\n",
        "                with open(full_eval_path, 'a') as full_file, open(onset_eval_path, 'a') as onset_file, open(offset_eval_path, 'a') as offset_file:\n",
        "                    full_file.write(f\"{predicted_file}, {results['full'][0]}, {results['full'][1]}, {results['full'][2]}\\n\")\n",
        "                    onset_file.write(f\"{predicted_file}, {results['onset'][0]}, {results['onset'][1]}, {results['onset'][2]}\\n\")\n",
        "                    offset_file.write(f\"{predicted_file}, {results['offset'][0]}, {results['offset'][1]}, {results['offset'][2]}\\n\")\n",
        "\n",
        "            except ValueError as e:\n",
        "                print(\"Error\")\n",
        "                pass\n",
        "\n",
        "    def calculate_and_save_averages(scores, file_path):\n",
        "        if scores:  # Ensure there are scores to calculate averages\n",
        "            avg_precision = sum(score[0] for score in scores) / len(scores)\n",
        "            avg_recall = sum(score[1] for score in scores) / len(scores)\n",
        "            avg_f1 = sum(score[2] for score in scores) / len(scores)\n",
        "            with open(file_path, 'w') as file:\n",
        "                file.write(f\"Average Precision, Average Recall, Average F1 Score\\n\")\n",
        "                file.write(f\"{avg_precision}, {avg_recall}, {avg_f1}\\n\")\n",
        "\n",
        "    calculate_and_save_averages(full_scores, full_avg_path)\n",
        "    calculate_and_save_averages(onset_scores, onset_avg_path)\n",
        "    calculate_and_save_averages(offset_scores, offset_avg_path)\n",
        "\n",
        "# Usage example\n",
        "predicted_folder = \"OMAPS/evaluation/attack-delay\"\n",
        "truth_folder = \"OMAPS/complete/text\"\n",
        "\n",
        "evaluate_folders(predicted_folder, truth_folder, predicted_folder)\n"
      ],
      "metadata": {
        "id": "_ybuVIrwBKYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9926e026-334f-4075-a21f-d32dce4a55bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_intervals, predicted_pitches = read_note_data_from_npy(\"OMAPS2/evaluation/attack-delay/01_01-transcription.npy\")\n",
        "truth_intervals, truth_pitches = read_note_data_from_text(\"OMAPS2/complete/text/01_01.txt\")\n",
        "\n",
        "print(\"Predicted Intervals:\", predicted_intervals)\n",
        "print(\"Predicted Pitches:\", predicted_pitches)\n",
        "print(\"Truth Intervals:\", truth_intervals)\n",
        "print(\"Truth Pitches:\", truth_pitches)"
      ],
      "metadata": {
        "id": "OqpXCPLgNk4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "bc33ab1c-bf2c-4d7d-8b76-3aed3a33f02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'OMAPS2/evaluation/attack-delay/01_01-transcription.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-642a3be4d7a1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_pitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_note_data_from_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OMAPS2/evaluation/attack-delay/01_01-transcription.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtruth_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_pitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_note_data_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OMAPS2/complete/text/01_01.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Intervals:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Pitches:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_pitches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-734acb71cdf9>\u001b[0m in \u001b[0;36mread_note_data_from_npy\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;34m\"\"\"Read note data from a .npy file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Load data from the .npy file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Extract start time, end time, and pitch from the loaded data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OMAPS2/evaluation/attack-delay/01_01-transcription.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzHXA8d5SPOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}