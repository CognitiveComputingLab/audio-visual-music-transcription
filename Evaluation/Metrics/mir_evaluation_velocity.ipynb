{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSVSBh0xBDIC",
        "outputId": "4fbf69fa-d85f-4c65-b03c-a21e2001147c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval) (0.18.3)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi, mir_eval\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=d49aa2f16a3fe473650b2b8e3aa377b0ffc831662570de7f97ee538a844a409a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100704 sha256=a8fb8374053a3386ae2aebdb0ae33d728ab603258989859088979bfe5e6e35a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n",
            "Successfully built pretty_midi mir_eval\n",
            "Installing collected packages: packaging, mir_eval, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed mido-1.3.2 mir_eval-0.7 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi mir_eval numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK9FpIshBIWY",
        "outputId": "4808f03c-e961-40a0-ad24-8585513a2a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pretty_midi\n",
        "import mir_eval\n",
        "import numpy as np\n",
        "\n",
        "def read_note_data_from_text(file_path):\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    velocities = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            columns = line.strip().split()\n",
        "            start, end, pitch, velocity = columns\n",
        "            intervals.append([float(start), float(end)])\n",
        "            pitches.append(int(pitch))\n",
        "            velocities.append(int(velocity))\n",
        "    return np.array(intervals), np.array(pitches), np.array(velocities)\n",
        "\n",
        "def prepare_data_for_evaluation(midi_file):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    velocities = []\n",
        "    for instrument in midi_data.instruments:\n",
        "        for note in instrument.notes:\n",
        "            intervals.append([note.start, note.end])\n",
        "            pitches.append(note.pitch)\n",
        "            velocities.append(note.velocity)\n",
        "    return np.array(intervals), np.array(pitches), np.array(velocities)\n",
        "\n",
        "def read_note_data_from_npy(file_path):\n",
        "    data = np.load(file_path)\n",
        "    intervals = data[:, :2]\n",
        "    pitches = data[:, 2]\n",
        "    return intervals, pitches\n",
        "\n",
        "def evaluate_midi(predicted_midi_file, truth_midi_file):\n",
        "    predicted_intervals, predicted_pitches, predicted_velocities = prepare_data_for_evaluation(predicted_midi_file)\n",
        "    truth_intervals, truth_pitches, truth_velocities = read_note_data_from_text(truth_midi_file)\n",
        "\n",
        "    full_precision, full_recall, full_f1_score, overlap = mir_eval.transcription_velocity.precision_recall_f1_overlap(\n",
        "        truth_intervals, truth_pitches, truth_velocities,\n",
        "        predicted_intervals, predicted_pitches, predicted_velocities,\n",
        "        onset_tolerance=0.05, pitch_tolerance=50.0, offset_ratio=None,\n",
        "        offset_min_tolerance=0.05, strict=False, velocity_tolerance=0.1, beta=1.0)\n",
        "\n",
        "    onset_precision, onset_recall, onset_f1_score = mir_eval.transcription.onset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, onset_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    offset_precision, offset_recall, offset_f1_score = mir_eval.transcription.offset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, offset_ratio=0.2, offset_min_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    return {\n",
        "        'full': (full_precision, full_recall, full_f1_score),\n",
        "        'onset': (onset_precision, onset_recall, onset_f1_score),\n",
        "        'offset': (offset_precision, offset_recall, offset_f1_score),\n",
        "        'overlap': overlap\n",
        "    }\n",
        "\n",
        "def evaluate_folders(predicted_folder, truth_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    full_eval_path = os.path.join(output_folder, \"full_evaluation_results.txt\")\n",
        "    onset_eval_path = os.path.join(output_folder, \"onset_evaluation_results.txt\")\n",
        "    offset_eval_path = os.path.join(output_folder, \"offset_evaluation_results.txt\")\n",
        "    overlap_eval_path = os.path.join(output_folder, \"overlap_evaluation_results.txt\")\n",
        "    full_avg_path = os.path.join(output_folder, \"full_evaluation_average.txt\")\n",
        "    onset_avg_path = os.path.join(output_folder, \"onset_evaluation_average.txt\")\n",
        "    offset_avg_path = os.path.join(output_folder, \"offset_evaluation_average.txt\")\n",
        "    overlap_avg_path = os.path.join(output_folder, \"overlap_evaluation_average.txt\")\n",
        "\n",
        "    full_scores = []\n",
        "    onset_scores = []\n",
        "    offset_scores = []\n",
        "    overlap_scores = []\n",
        "\n",
        "    with open(full_eval_path, 'w') as full_file, open(onset_eval_path, 'w') as onset_file, \\\n",
        "         open(offset_eval_path, 'w') as offset_file, open(overlap_eval_path, 'w') as overlap_file:\n",
        "        full_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "        onset_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "        offset_file.write(\"File, Precision, Recall, F1 Score\\n\")\n",
        "        overlap_file.write(\"File, Overlap\\n\")\n",
        "\n",
        "    for predicted_file in os.listdir(predicted_folder):\n",
        "        if not predicted_file.endswith('.mid'):\n",
        "            continue\n",
        "\n",
        "        predicted_path = os.path.join(predicted_folder, predicted_file)\n",
        "        truth_file = predicted_file.rsplit('.', 1)[0] + '.txt'\n",
        "        truth_path = os.path.join(truth_folder, truth_file)\n",
        "\n",
        "        if os.path.isfile(truth_path):\n",
        "            try:\n",
        "                results = evaluate_midi(predicted_path, truth_path)\n",
        "\n",
        "                full_scores.append(results['full'])\n",
        "                onset_scores.append(results['onset'])\n",
        "                offset_scores.append(results['offset'])\n",
        "                overlap_scores.append(results['overlap'])\n",
        "\n",
        "                with open(full_eval_path, 'a') as full_file, open(onset_eval_path, 'a') as onset_file, \\\n",
        "                     open(offset_eval_path, 'a') as offset_file, open(overlap_eval_path, 'a') as overlap_file:\n",
        "                    full_file.write(f\"{predicted_file}, {results['full'][0]}, {results['full'][1]}, {results['full'][2]}\\n\")\n",
        "                    onset_file.write(f\"{predicted_file}, {results['onset'][0]}, {results['onset'][1]}, {results['onset'][2]}\\n\")\n",
        "                    offset_file.write(f\"{predicted_file}, {results['offset'][0]}, {results['offset'][1]}, {results['offset'][2]}\\n\")\n",
        "                    overlap_file.write(f\"{predicted_file}, {results['overlap']}\\n\")\n",
        "\n",
        "            except ValueError as e:\n",
        "                # Error\n",
        "                pass\n",
        "\n",
        "    def calculate_and_save_averages(scores, file_path):\n",
        "        if scores:\n",
        "            avg_precision = sum(score[0] for score in scores) / len(scores)\n",
        "            avg_recall = sum(score[1] for score in scores) / len(scores)\n",
        "            avg_f1 = sum(score[2] for score in scores) / len(scores)\n",
        "            with open(file_path, 'w') as file:\n",
        "                file.write(f\"Average Precision, Average Recall, Average F1 Score, Average Velocity, Average Overlap\\n\")\n",
        "                file.write(f\"{avg_precision}, {avg_recall}, {avg_f1}\\n\")\n",
        "\n",
        "    def calculate_and_save_average_overlap(scores, file_path):\n",
        "        if scores:\n",
        "            avg_overlap = sum(scores) / len(scores)\n",
        "            with open(file_path, 'w') as file:\n",
        "                file.write(f\"Average Overlap\\n\")\n",
        "                file.write(f\"{avg_overlap}\\n\")\n",
        "\n",
        "    calculate_and_save_averages(full_scores, full_avg_path)\n",
        "    calculate_and_save_averages(onset_scores, onset_avg_path)\n",
        "    calculate_and_save_averages(offset_scores, offset_avg_path)\n",
        "    calculate_and_save_average_overlap(overlap_scores, overlap_avg_path)\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code\")\n",
        "predicted_folder = \"OMAPS2/evaluation/skipping-the-frame-level\"\n",
        "truth_folder = \"OMAPS2/complete/text\"\n",
        "\n",
        "evaluate_folders(predicted_folder, truth_folder, predicted_folder)\n"
      ],
      "metadata": {
        "id": "_ybuVIrwBKYn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "ba27e360-92ea-4ebf-cbc5-b13993d0a628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pretty_midi'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b43f62cf4709>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpretty_midi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmir_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pretty_midi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OqpXCPLgNk4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "a491808a-4b0a-4baf-d794-91c07c663e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'read_note_data_from_npy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5f110e2f862>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_pitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_note_data_from_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_midi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtruth_intervals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_pitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_note_data_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_midi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Intervals:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Pitches:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_pitches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_note_data_from_npy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "raTG9w9HSGd6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}