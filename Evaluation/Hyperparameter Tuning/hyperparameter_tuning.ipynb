{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD5GTZKxRPCs",
        "outputId": "2222f1ed-35f0-437d-9a5e-af0da92eda8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval) (0.18.3)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi, mir_eval\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=e773c83319849225fd58d97866b3377fed092c25c2190331fd301c8820da5007\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100704 sha256=4846331c59b908599be5f4870d139350cfbd2758c1222cc7caf2e5be0ae44e21\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n",
            "Successfully built pretty_midi mir_eval\n",
            "Installing collected packages: packaging, mir_eval, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed mido-1.3.2 mir_eval-0.7 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi mir_eval numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42KrutwyRlcB",
        "outputId": "fb001c25-e796-444a-b04c-e65f56606e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/piano-vision\")\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SmXEsR0bUfg",
        "outputId": "d1e8f2d8-e9d5-4158-878d-2a14c4e634c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Collecting ncls (from -r requirements.txt (line 1))\n",
            "  Downloading ncls-0.0.68-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.2.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.2.1+cu121)\n",
            "Requirement already satisfied: mir_eval in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.7)\n",
            "Collecting pydub (from -r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.7.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.2)\n",
            "Collecting torch_optimizer (from -r requirements.txt (line 12))\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sox (from -r requirements.txt (line 13))\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soxr in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ncls->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval->-r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.0.2)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch_optimizer->-r requirements.txt (line 12))\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 10)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 10)) (3.2.2)\n",
            "Building wheels for collected packages: sox\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40038 sha256=cf445feadf82914db391c5544043406c6f0f1fafdd3489acef56e2d4164b1480\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n",
            "Successfully built sox\n",
            "Installing collected packages: pydub, sox, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ncls, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ranger, torch_optimizer\n",
            "Successfully installed ncls-0.0.68 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pydub-0.25.1 pytorch-ranger-0.1.1 sox-1.5.0 torch_optimizer-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pretty_midi\n",
        "import mir_eval\n",
        "import numpy as np\n",
        "import itertools\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "def read_note_data_from_text(file_path):\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            start, end, pitch = line.strip().split()\n",
        "            intervals.append([float(start), float(end)])\n",
        "            pitches.append(int(pitch))\n",
        "    # print(np.array(intervals))\n",
        "    return np.array(intervals), np.array(pitches)\n",
        "\n",
        "def prepare_data_for_evaluation(midi_file):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    intervals = []\n",
        "    pitches = []\n",
        "    for instrument in midi_data.instruments:\n",
        "        for note in instrument.notes:\n",
        "            intervals.append([note.start, note.end])\n",
        "            pitches.append(note.pitch)\n",
        "    return np.array(intervals), np.array(pitches)\n",
        "\n",
        "def evaluate_midi(predicted_midi_file, truth_midi_file):\n",
        "    predicted_intervals, predicted_pitches = prepare_data_for_evaluation(predicted_midi_file)\n",
        "    truth_intervals, truth_pitches = read_note_data_from_text(truth_midi_file)\n",
        "\n",
        "    # mir_eval.transcription.validate(truth_intervals, truth_pitches, predicted_intervals, predicted_pitches)\n",
        "\n",
        "    full_precision, full_recall, full_f1_score, _ = mir_eval.transcription.precision_recall_f1_overlap(\n",
        "        truth_intervals, truth_pitches, predicted_intervals, predicted_pitches,\n",
        "        onset_tolerance=0.05, pitch_tolerance=50.0, offset_ratio=None, offset_min_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    onset_precision, onset_recall, onset_f1_score = mir_eval.transcription.onset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, onset_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    offset_precision, offset_recall, offset_f1_score = mir_eval.transcription.offset_precision_recall_f1(\n",
        "        truth_intervals, predicted_intervals, offset_ratio=0.2, offset_min_tolerance=0.05, strict=False, beta=1.0)\n",
        "\n",
        "    return {\n",
        "        'full': (full_precision, full_recall, full_f1_score),\n",
        "        'onset': (onset_precision, onset_recall, onset_f1_score),\n",
        "        'offset': (offset_precision, offset_recall, offset_f1_score)\n",
        "    }\n",
        "\n",
        "def run_transcription_and_evaluate(input_video_path, output_midi_path, segment_size, segment_hop_size):\n",
        "    command = f\"python -m transkun.transcribe {input_video_path} {output_midi_path} --segmentHopSize {segment_hop_size} --segmentSize {segment_size} --device cuda\"\n",
        "    subprocess.run(command, check=True, shell=True)\n",
        "    results = evaluate_midi(output_midi_path, truth_midi_path)\n",
        "    full_f1_score = results['full'][2]\n",
        "    return full_f1_score\n"
      ],
      "metadata": {
        "id": "a89-eKfoRm-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "input_directory = \"../OMAPS/complete/mp4-tuning\"\n",
        "output_directory = \"../OMAPS/evaluation/audio-visual-fusion-tuning-4\"\n",
        "truth_folder = \"../OMAPS/complete/text-tuning\"\n",
        "\n",
        "segment_sizes = [6, 8, 12, 16, 32, 64]\n",
        "hop_size_ratios = [0.5, 0.75]\n",
        "\n",
        "for segment_size, ratio in itertools.product(segment_sizes, hop_size_ratios):\n",
        "    segment_hop_size = segment_size * ratio\n",
        "\n",
        "    for filename in os.listdir(input_directory):\n",
        "        if filename.endswith(\".mp4\"):\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "            modified_output_filename = f\"{base_name}_seg{segment_size}_hop{segment_hop_size}.mid\"\n",
        "            input_video_path = os.path.join(input_directory, filename)\n",
        "            output_midi_path = os.path.join(output_directory, modified_output_filename)\n",
        "            truth_midi_path = os.path.join(truth_folder, base_name + \".txt\")\n",
        "            print(f\"Processing with segment size {segment_size} and hop size {segment_hop_size}\")\n",
        "\n",
        "            start_time = time.time()\n",
        "            try:\n",
        "                f1_score = run_transcription_and_evaluate(input_video_path, output_midi_path, segment_size, segment_hop_size)\n",
        "                processing_time = time.time() - start_time\n",
        "\n",
        "                results[(segment_size, segment_hop_size)] = results.get((segment_size, segment_hop_size), []) + [f1_score]\n",
        "\n",
        "                combination_result_path = os.path.join(output_directory, f\"results_seg{segment_size}_hop{segment_hop_size}.txt\")\n",
        "                with open(combination_result_path, 'a') as combo_file:\n",
        "                    combo_file.write(f\"{filename}: F1 Score = {f1_score}, Processing Time = {processing_time} seconds\\n\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "average_f1_scores = {k: sum(v) / len(v) for k, v in results.items()}\n",
        "best_parameters = max(average_f1_scores, key=average_f1_scores.get)\n",
        "best_f1_score = average_f1_scores[best_parameters]\n",
        "\n",
        "output_file_path = \"/content/drive/MyDrive/Dissertation Code/OMAPS/evaluation/audio-visual-fusion-tuning-2/evaluation_results.txt\"\n",
        "\n",
        "with open(output_file_path, 'w') as file:\n",
        "    file.write(\"Best Parameters:\\n\")\n",
        "    file.write(f\"Segment Size: {best_parameters[0]}, Hop Size: {best_parameters[1]}\\n\")\n",
        "    file.write(f\"Best F1 Score: {best_f1_score}\\n\")\n",
        "\n",
        "print(f\"Best Parameters: Segment Size = {best_parameters[0]}, Hop Size = {best_parameters[1]}\")\n",
        "print(f\"Best Average F1 Score: {best_f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqt_5NCKSN81",
        "outputId": "cce93210-81c7-4a55-ba1a-b4b4a7571e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with segment size 6 and hop size 3.0...\n",
            "Processing with segment size 6 and hop size 3.0...\n",
            "Processing with segment size 6 and hop size 3.0...\n",
            "Processing with segment size 6 and hop size 3.0...\n",
            "Processing with segment size 6 and hop size 3.0...\n",
            "Processing with segment size 6 and hop size 4.5...\n",
            "Processing with segment size 6 and hop size 4.5...\n",
            "Processing with segment size 6 and hop size 4.5...\n",
            "Processing with segment size 6 and hop size 4.5...\n",
            "Processing with segment size 6 and hop size 4.5...\n",
            "Processing with segment size 8 and hop size 4.0...\n",
            "Processing with segment size 8 and hop size 4.0...\n",
            "Processing with segment size 8 and hop size 4.0...\n",
            "Processing with segment size 8 and hop size 4.0...\n",
            "Processing with segment size 8 and hop size 4.0...\n",
            "Processing with segment size 8 and hop size 6.0...\n",
            "Processing with segment size 8 and hop size 6.0...\n",
            "Processing with segment size 8 and hop size 6.0...\n",
            "Processing with segment size 8 and hop size 6.0...\n",
            "Processing with segment size 8 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 6.0...\n",
            "Processing with segment size 12 and hop size 9.0...\n",
            "Processing with segment size 12 and hop size 9.0...\n",
            "Processing with segment size 12 and hop size 9.0...\n",
            "Processing with segment size 12 and hop size 9.0...\n",
            "Processing with segment size 12 and hop size 9.0...\n",
            "Processing with segment size 16 and hop size 8.0...\n",
            "Processing with segment size 16 and hop size 8.0...\n",
            "Processing with segment size 16 and hop size 8.0...\n",
            "Processing with segment size 16 and hop size 8.0...\n",
            "Processing with segment size 16 and hop size 8.0...\n",
            "Processing with segment size 16 and hop size 12.0...\n",
            "Processing with segment size 16 and hop size 12.0...\n",
            "Processing with segment size 16 and hop size 12.0...\n",
            "Processing with segment size 16 and hop size 12.0...\n",
            "Processing with segment size 16 and hop size 12.0...\n",
            "Processing with segment size 32 and hop size 16.0...\n",
            "Processing with segment size 32 and hop size 16.0...\n",
            "Processing with segment size 32 and hop size 16.0...\n",
            "Processing with segment size 32 and hop size 16.0...\n",
            "Processing with segment size 32 and hop size 16.0...\n",
            "Processing with segment size 32 and hop size 24.0...\n",
            "Processing with segment size 32 and hop size 24.0...\n",
            "Processing with segment size 32 and hop size 24.0...\n",
            "Processing with segment size 32 and hop size 24.0...\n",
            "Processing with segment size 32 and hop size 24.0...\n",
            "Processing with segment size 64 and hop size 32.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/001.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/001_seg64_hop32.0.mid --segmentHopSize 32.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 32.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/002.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/002_seg64_hop32.0.mid --segmentHopSize 32.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 32.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/003.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/003_seg64_hop32.0.mid --segmentHopSize 32.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 32.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/004.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/004_seg64_hop32.0.mid --segmentHopSize 32.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 32.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/010.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/010_seg64_hop32.0.mid --segmentHopSize 32.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 48.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/001.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/001_seg64_hop48.0.mid --segmentHopSize 48.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 48.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/002.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/002_seg64_hop48.0.mid --segmentHopSize 48.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 48.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/003.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/003_seg64_hop48.0.mid --segmentHopSize 48.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 48.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/004.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/004_seg64_hop48.0.mid --segmentHopSize 48.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Processing with segment size 64 and hop size 48.0...\n",
            "An error occurred: Command 'python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/010.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-4/010_seg64_hop48.0.mid --segmentHopSize 48.0 --segmentSize 64 --device cuda' returned non-zero exit status 1.\n",
            "Best Parameters: Segment Size = 32, Hop Size = 24.0\n",
            "Best Average F1 Score: 0.8229090924899257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m transkun.transcribe ../OMAPS/complete/mp4-tuning/001.mp4 ../OMAPS/evaluation/audio-visual-fusion-tuning-2/001.mid --segmentHopSize 3 --segmentSize 3.5 --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlnZrCiaZons",
        "outputId": "daf0378f-00f3-4de5-b8da-f81f219cc437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "Using device: cuda\n",
            "MoviePy - Writing audio in ../OMAPS/complete/mp4-tuning/001.mp3\n",
            "MoviePy - Done.\n",
            "DONE\n",
            "36 black keys found\n",
            "49 white keys found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w1svHu2Kdj8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}