{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Requirements for the Audio Model**"
      ],
      "metadata": {
        "id": "xUH-HRerP_Dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "NdXaUZDqEjyC",
        "outputId": "8bbfc1ed-674b-44d3-d297-24d7fe1aa72e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 \"/content/drive/MyDrive/Dissertation Code/main.py\" --img_dir \"/content/drive/MyDrive/Bobby Floyd - Georgia on My Mind.mkv\"\n",
        "!ls \"/content/drive/My Drive/Dissertation Code/Skipping-The-Frame-Level\"\n",
        "!cd \"/content/drive/My Drive/Dissertation Code/Skipping-The-Frame-Level\""
      ],
      "metadata": {
        "id": "Ye2OTR7QFo5b",
        "outputId": "28f8549e-046e-4132-da8e-eb8bdbc2468a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t    fallenDown.mid  grandPiano.mid  LICENSE\t  output.mid  requirements.txt\ttranskun\n",
            "checkpoint  fallenDown.mp3  grandPiano.mp3  midiSite.txt  README.md   setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# cd to the correct directory ensuring the folders are organised as in the readme\n",
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "# Install the requirements\n",
        "!pip3 install -r \"requirements.txt\"\n",
        "!apt-get install sox\n",
        "!pip install sox"
      ],
      "metadata": {
        "id": "kLk_WVpLGKx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5aa34b-0e93-47e6-e284-d6cb09e3fc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ncls in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.0.68)\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.2.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu121)\n",
            "Requirement already satisfied: mir_eval in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.7.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.4.1)\n",
            "Requirement already satisfied: soxr in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ncls->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval->-r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 8)) (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer->-r requirements.txt (line 12)) (0.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 10)) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 10)) (3.2.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sox) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Pre-Processing for the Audio Model**"
      ],
      "metadata": {
        "id": "3oUKMRcXQXjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "# Create the pickle files from the dataset\n",
        "!python3 \"transkun/convert-to-pickle.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0m2wCR8d0R1",
        "outputId": "00c82eaf-aaf2-45e9-ad48-b528d6058ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          split             midi_filename                     audio_filename  duration\n",
            "0          test   complete/MIDI/01_01.mid   complete/wav_converted/01_01.wav    107.05\n",
            "1          test   complete/MIDI/01_02.mid   complete/wav_converted/01_02.wav    100.05\n",
            "2          test   complete/MIDI/01_03.mid   complete/wav_converted/01_03.wav    106.03\n",
            "3    validation   complete/MIDI/01_04.mid   complete/wav_converted/01_04.wav    132.05\n",
            "4         train   complete/MIDI/01_05.mid   complete/wav_converted/01_05.wav    117.03\n",
            "..          ...                       ...                                ...       ...\n",
            "201       train  complete/MIDI/yty5_4.mid  complete/wav_converted/yty5_4.wav    128.00\n",
            "202       train  complete/MIDI/yty5_5.mid  complete/wav_converted/yty5_5.wav    106.00\n",
            "203       train    complete/MIDI/zyn1.mid    complete/wav_converted/zyn1.wav    131.00\n",
            "204       train    complete/MIDI/zyn2.mid    complete/wav_converted/zyn2.wav    170.00\n",
            "205       train    complete/MIDI/zyn3.mid    complete/wav_converted/zyn3.wav    118.00\n",
            "\n",
            "[206 rows x 4 columns]\n",
            "Pickles have been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training the Audio Model**"
      ],
      "metadata": {
        "id": "9a8m9b6nRJoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "#!python3 -m transkun.train --nProcess 1 --datasetPath \"../OMAPS2\" --datasetMetaFile_train \"transkun/train.pickle\" --datasetMetaFile_val \"transkun/validation.pickle\" --batchSize 32 --max_lr 0.001 --nIter 100 --modelConf \"checkpoint/conf.json\" --augment \"../OMAPS2/weights/weights.pth\"\n",
        "\n",
        "!python3 -m transkun.train --nProcess 1 \\\n",
        "                           --datasetPath \"../OMAPS2\" \\\n",
        "                           --datasetMetaFile_train \"transkun/train.pickle\" \\\n",
        "                           --datasetMetaFile_val \"transkun/validation.pickle\" \\\n",
        "                           --batchSize 4 \\\n",
        "                           --max_lr 0.0001 \\\n",
        "                           --nIter 12000 \\\n",
        "                           --modelConf \"checkpoint/conf.json\" \\\n",
        "                           --augment \\\n",
        "                           \"../OMAPS2/weights/weights20.pth\"\n",
        "\n",
        "# !python3 -m transkun.train --nProcess 1 \\\n",
        "#                            --datasetPath \"../OMAPS2\" \\\n",
        "#                            --datasetMetaFile_train \"transkun/train.pickle\" \\\n",
        "#                            --datasetMetaFile_val \"transkun/validation.pickle\" \\\n",
        "#                            --batchSize 8 \\\n",
        "#                            --max_lr 0.001 \\\n",
        "#                            --nIter 12000 \\\n",
        "#                            --modelConf \"checkpoint/conf.json\" \\\n",
        "#                            --augment \\\n",
        "#                            \"../OMAPS2/weights/weights2.pth\"\n",
        "\n",
        "# !python3 -m transkun.train --nProcess 1 \\\n",
        "#                            --datasetPath \"../OMAPS2\" \\\n",
        "#                            --datasetMetaFile_train \"transkun/train.pickle\" \\\n",
        "#                            --datasetMetaFile_val \"transkun/validation.pickle\" \\\n",
        "#                            --batchSize 6 \\\n",
        "#                            --max_lr 0.001 \\\n",
        "#                            --nIter 9000 \\\n",
        "#                            --modelConf \"checkpoint/conf.json\" \\\n",
        "#                            --augment \\\n",
        "#                            \"../OMAPS2/weights/weights2.pth\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLQqquUYO2N",
        "outputId": "0709e839-4210-49b2-bc47-14f198435592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 19:27:23.871496: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-24 19:27:23.924696: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 19:27:23.924743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 19:27:23.926458: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 19:27:23.934619: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 19:27:25.061042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "#0 loaded\n",
            "loading dataset....\n",
            "loading the annotation file...\n",
            "n: 147  totalDuration:  17182.9  elapsed: 0.3580193519592285\n",
            "creating index for notes in all pieces...\n",
            "elapsed: 0.040363311767578125\n",
            "loading the annotation file...\n",
            "n: 19  totalDuration:  2536.41  elapsed: 0.016062021255493164\n",
            "creating index for notes in all pieces...\n",
            "elapsed: 0.0044591426849365234\n",
            "#0 loaded\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/mir_eval/transcription_velocity.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  slope, intercept = np.linalg.lstsq(\n",
            "/usr/local/lib/python3.10/dist-packages/torch_optimizer/adabelief.py:218: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  p.data.add_(-group['lr'], exp_avg)\n",
            "epoch:0 progress:0.000 step:0  loss:5934.9697 gradNorm:12.03 clipValue:40.00 time:17.22 \n",
            "nGT:503.0001 nEst:292321.0001 nCorrect:123.0001\n",
            "f1:0.0008400957566045846 precision:0.00042077065950760613 recall:0.24453295337317033\n",
            "f1Frame:0.02878289891937999 precisionFrame:0.01468637206537645 recallFrame:0.7166564286691983\n",
            "mseVelocity:237.6192059902175 mseOF:0.1688840314194427\n",
            "epoch:0 progress:0.002 step:0  loss:5927.6807 gradNorm:12.05 clipValue:34.41 time:3.08 \n",
            "epoch:0 progress:0.004 step:0  loss:5932.9854 gradNorm:11.99 clipValue:28.82 time:2.37 \n",
            "epoch:0 progress:0.006 step:0  loss:5923.1533 gradNorm:12.02 clipValue:23.23 time:2.38 \n",
            "epoch:0 progress:0.008 step:0  loss:5926.9761 gradNorm:11.96 clipValue:17.64 time:2.37 \n",
            "epoch:0 progress:0.010 step:0  loss:5936.7432 gradNorm:11.98 clipValue:12.05 time:2.42 \n",
            "epoch:0 progress:0.012 step:0  loss:5929.6890 gradNorm:12.02 clipValue:12.05 time:2.40 \n",
            "epoch:0 progress:0.014 step:0  loss:5935.3682 gradNorm:11.94 clipValue:12.04 time:2.40 \n",
            "epoch:0 progress:0.016 step:0  loss:5920.2314 gradNorm:11.97 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.019 step:0  loss:5925.4551 gradNorm:12.01 clipValue:12.04 time:2.40 \n",
            "epoch:0 progress:0.021 step:0  loss:5923.5200 gradNorm:11.99 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.023 step:0  loss:5938.8672 gradNorm:11.95 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.025 step:0  loss:5953.9033 gradNorm:11.95 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.027 step:0  loss:5934.5342 gradNorm:12.05 clipValue:12.03 time:2.41 \n",
            "epoch:0 progress:0.029 step:0  loss:5939.9556 gradNorm:11.97 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.031 step:0  loss:5932.3491 gradNorm:12.03 clipValue:12.03 time:2.41 \n",
            "epoch:0 progress:0.033 step:0  loss:5926.6846 gradNorm:12.00 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.035 step:0  loss:5939.9463 gradNorm:11.98 clipValue:12.03 time:2.41 \n",
            "epoch:0 progress:0.037 step:0  loss:5915.1064 gradNorm:12.05 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.039 step:0  loss:5935.8296 gradNorm:11.94 clipValue:12.04 time:2.37 \n",
            "epoch:0 progress:0.041 step:0  loss:5930.7412 gradNorm:12.03 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.043 step:0  loss:5939.7197 gradNorm:11.95 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.045 step:0  loss:5918.4087 gradNorm:12.04 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.047 step:0  loss:5916.8682 gradNorm:11.98 clipValue:12.04 time:2.40 \n",
            "epoch:0 progress:0.049 step:0  loss:5926.3647 gradNorm:11.96 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.051 step:0  loss:5930.4424 gradNorm:12.03 clipValue:12.03 time:2.40 \n",
            "epoch:0 progress:0.053 step:0  loss:5929.6392 gradNorm:11.97 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.056 step:0  loss:5921.8281 gradNorm:12.00 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.058 step:0  loss:5928.7915 gradNorm:11.99 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.060 step:0  loss:5939.0405 gradNorm:12.01 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.062 step:0  loss:5937.7993 gradNorm:11.94 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.064 step:0  loss:5923.0146 gradNorm:11.98 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.066 step:0  loss:5928.1050 gradNorm:11.98 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.068 step:0  loss:5919.8647 gradNorm:12.03 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.070 step:0  loss:5912.3872 gradNorm:12.08 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.072 step:0  loss:5921.4312 gradNorm:12.00 clipValue:12.03 time:2.40 \n",
            "epoch:0 progress:0.074 step:0  loss:5913.3101 gradNorm:12.02 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.076 step:0  loss:5929.8872 gradNorm:11.99 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.078 step:0  loss:5930.1279 gradNorm:12.01 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.080 step:0  loss:5923.6890 gradNorm:11.99 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.082 step:0  loss:5932.7476 gradNorm:12.02 clipValue:12.03 time:14.11 \n",
            "nGT:622.0001 nEst:275030.0001 nCorrect:119.0001\n",
            "f1:0.0008634082097257351 precision:0.00043268043470433027 recall:0.1913184579873862\n",
            "f1Frame:0.03312930133553185 precisionFrame:0.016968795830896357 recallFrame:0.6954980557338168\n",
            "mseVelocity:148.33011079901758 mseOF:0.16347158815126572\n",
            "epoch:0 progress:0.084 step:0  loss:5911.6294 gradNorm:11.96 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.086 step:0  loss:5914.3047 gradNorm:12.05 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.088 step:0  loss:5923.2500 gradNorm:12.02 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.091 step:0  loss:5928.8906 gradNorm:12.02 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.093 step:0  loss:5905.4146 gradNorm:12.05 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.095 step:0  loss:5915.0850 gradNorm:12.01 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.097 step:0  loss:5914.1968 gradNorm:12.04 clipValue:12.03 time:2.40 \n",
            "epoch:0 progress:0.099 step:0  loss:5915.4702 gradNorm:12.00 clipValue:12.03 time:2.39 \n",
            "epoch:0 progress:0.101 step:0  loss:5906.6553 gradNorm:12.06 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.103 step:0  loss:5921.0244 gradNorm:12.03 clipValue:12.03 time:2.37 \n",
            "epoch:0 progress:0.105 step:0  loss:5912.4966 gradNorm:12.03 clipValue:12.03 time:2.38 \n",
            "epoch:0 progress:0.107 step:0  loss:5915.8228 gradNorm:12.09 clipValue:12.03 time:2.42 \n",
            "epoch:0 progress:0.109 step:0  loss:5907.1533 gradNorm:12.12 clipValue:12.04 time:2.40 \n",
            "epoch:0 progress:0.111 step:0  loss:5917.3857 gradNorm:12.06 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.113 step:0  loss:5929.0098 gradNorm:12.04 clipValue:12.04 time:2.39 \n",
            "epoch:0 progress:0.115 step:0  loss:5917.0093 gradNorm:12.08 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.117 step:0  loss:5904.7959 gradNorm:12.07 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.119 step:0  loss:5912.4175 gradNorm:12.11 clipValue:12.05 time:2.40 \n",
            "epoch:0 progress:0.121 step:0  loss:5921.9062 gradNorm:12.10 clipValue:12.05 time:2.38 \n",
            "epoch:0 progress:0.123 step:0  loss:5907.0195 gradNorm:12.14 clipValue:12.05 time:2.38 \n",
            "epoch:0 progress:0.126 step:0  loss:5912.7598 gradNorm:12.16 clipValue:12.05 time:2.38 \n",
            "epoch:0 progress:0.128 step:0  loss:5912.1421 gradNorm:12.14 clipValue:12.05 time:2.37 \n",
            "epoch:0 progress:0.130 step:0  loss:5900.8286 gradNorm:12.20 clipValue:12.06 time:2.38 \n",
            "epoch:0 progress:0.132 step:0  loss:5903.2021 gradNorm:12.14 clipValue:12.06 time:2.37 \n",
            "epoch:0 progress:0.134 step:0  loss:5911.0771 gradNorm:12.23 clipValue:12.06 time:2.38 \n",
            "epoch:0 progress:0.136 step:0  loss:5905.2812 gradNorm:12.19 clipValue:12.07 time:2.38 \n",
            "epoch:0 progress:0.138 step:0  loss:5915.0459 gradNorm:12.26 clipValue:12.07 time:2.41 \n",
            "epoch:0 progress:0.140 step:0  loss:5903.8726 gradNorm:12.24 clipValue:12.08 time:2.37 \n",
            "epoch:0 progress:0.142 step:0  loss:5910.8882 gradNorm:12.27 clipValue:12.08 time:2.37 \n",
            "epoch:0 progress:0.144 step:0  loss:5896.0835 gradNorm:12.29 clipValue:12.09 time:2.38 \n",
            "epoch:0 progress:0.146 step:0  loss:5887.2119 gradNorm:12.39 clipValue:12.10 time:2.37 \n",
            "epoch:0 progress:0.148 step:0  loss:5884.2998 gradNorm:12.41 clipValue:12.11 time:2.37 \n",
            "epoch:0 progress:0.150 step:0  loss:5901.1504 gradNorm:12.39 clipValue:12.11 time:2.37 \n",
            "epoch:0 progress:0.152 step:0  loss:5894.4194 gradNorm:12.36 clipValue:12.13 time:2.39 \n",
            "epoch:0 progress:0.154 step:0  loss:5887.0537 gradNorm:12.45 clipValue:12.14 time:2.38 \n",
            "epoch:0 progress:0.156 step:0  loss:5891.5234 gradNorm:12.57 clipValue:12.14 time:2.38 \n",
            "epoch:0 progress:0.158 step:0  loss:5894.2466 gradNorm:12.54 clipValue:12.14 time:2.37 \n",
            "epoch:0 progress:0.160 step:0  loss:5886.4307 gradNorm:12.49 clipValue:12.15 time:2.38 \n",
            "epoch:0 progress:0.163 step:0  loss:5883.4360 gradNorm:12.54 clipValue:12.17 time:2.38 \n",
            "epoch:0 progress:0.165 step:0  loss:5880.1035 gradNorm:12.65 clipValue:12.19 time:10.33 \n",
            "nGT:372.0001 nEst:183142.0001 nCorrect:38.0001\n",
            "f1:0.00041413843040406903 precision:0.00020748981653171322 recall:0.10215077899172609\n",
            "f1Frame:0.035018957193333825 precisionFrame:0.017974510734161307 recallFrame:0.6767797010355007\n",
            "mseVelocity:160.8617889148417 mseOF:0.1637092170762616\n",
            "epoch:0 progress:0.167 step:0  loss:5880.4072 gradNorm:12.70 clipValue:12.20 time:2.39 \n",
            "epoch:0 progress:0.169 step:0  loss:5884.1333 gradNorm:12.80 clipValue:12.22 time:2.38 \n",
            "epoch:0 progress:0.171 step:0  loss:5881.7256 gradNorm:12.89 clipValue:12.24 time:2.38 \n",
            "epoch:0 progress:0.173 step:0  loss:5878.5391 gradNorm:12.91 clipValue:12.25 time:2.38 \n",
            "epoch:0 progress:0.175 step:0  loss:5870.8892 gradNorm:12.97 clipValue:12.26 time:2.39 \n",
            "epoch:0 progress:0.177 step:0  loss:5864.7139 gradNorm:12.98 clipValue:12.27 time:2.38 \n",
            "epoch:0 progress:0.179 step:0  loss:5863.0415 gradNorm:13.11 clipValue:12.28 time:2.40 \n",
            "epoch:0 progress:0.181 step:0  loss:5894.2002 gradNorm:13.29 clipValue:12.32 time:2.39 \n",
            "epoch:0 progress:0.183 step:0  loss:5872.6128 gradNorm:13.20 clipValue:12.36 time:2.39 \n",
            "epoch:0 progress:0.185 step:0  loss:5874.3071 gradNorm:13.07 clipValue:12.39 time:2.39 \n",
            "epoch:0 progress:0.187 step:0  loss:5857.4326 gradNorm:13.31 clipValue:12.39 time:2.38 \n",
            "epoch:0 progress:0.189 step:0  loss:5857.5400 gradNorm:13.47 clipValue:12.40 time:2.38 \n",
            "epoch:0 progress:0.191 step:0  loss:5867.8486 gradNorm:13.62 clipValue:12.42 time:2.38 \n",
            "epoch:0 progress:0.193 step:0  loss:5848.6899 gradNorm:13.62 clipValue:12.46 time:2.38 \n",
            "epoch:0 progress:0.195 step:0  loss:5848.8467 gradNorm:13.81 clipValue:12.49 time:2.38 \n",
            "epoch:0 progress:0.198 step:0  loss:5846.9673 gradNorm:14.13 clipValue:12.53 time:2.41 \n",
            "epoch:0 progress:0.200 step:0  loss:5838.1021 gradNorm:13.73 clipValue:12.54 time:2.37 \n",
            "epoch:0 progress:0.202 step:0  loss:5844.0283 gradNorm:14.28 clipValue:12.55 time:2.37 \n",
            "epoch:0 progress:0.204 step:0  loss:5842.1899 gradNorm:14.54 clipValue:12.59 time:2.38 \n",
            "epoch:0 progress:0.206 step:0  loss:5836.0986 gradNorm:14.33 clipValue:12.65 time:2.39 \n",
            "epoch:0 progress:0.208 step:0  loss:5834.3018 gradNorm:14.61 clipValue:12.69 time:2.40 \n",
            "epoch:0 progress:0.210 step:0  loss:5824.7290 gradNorm:14.80 clipValue:12.76 time:2.40 \n",
            "epoch:0 progress:0.212 step:0  loss:5810.3691 gradNorm:14.87 clipValue:12.84 time:2.38 \n",
            "epoch:0 progress:0.214 step:0  loss:5819.6357 gradNorm:15.34 clipValue:12.90 time:2.39 \n",
            "epoch:0 progress:0.216 step:0  loss:5805.0107 gradNorm:15.68 clipValue:12.91 time:2.39 \n",
            "epoch:0 progress:0.218 step:0  loss:5813.0288 gradNorm:15.72 clipValue:12.95 time:2.38 \n",
            "epoch:0 progress:0.220 step:0  loss:5803.8760 gradNorm:15.08 clipValue:12.97 time:2.37 \n",
            "epoch:0 progress:0.222 step:0  loss:5804.0488 gradNorm:15.56 clipValue:13.01 time:2.38 \n",
            "epoch:0 progress:0.224 step:0  loss:5788.1333 gradNorm:16.59 clipValue:13.08 time:2.37 \n",
            "epoch:0 progress:0.226 step:0  loss:5785.5200 gradNorm:16.99 clipValue:13.11 time:2.38 \n",
            "epoch:0 progress:0.228 step:0  loss:5791.9014 gradNorm:16.46 clipValue:13.18 time:2.38 \n",
            "epoch:0 progress:0.230 step:0  loss:5784.2021 gradNorm:16.62 clipValue:13.25 time:2.38 \n",
            "epoch:0 progress:0.233 step:0  loss:5764.6670 gradNorm:17.42 clipValue:13.30 time:2.40 \n",
            "epoch:0 progress:0.235 step:0  loss:5758.3369 gradNorm:18.05 clipValue:13.34 time:2.38 \n",
            "epoch:0 progress:0.237 step:0  loss:5756.0967 gradNorm:18.10 clipValue:13.47 time:2.40 \n",
            "epoch:0 progress:0.239 step:0  loss:5752.2759 gradNorm:19.75 clipValue:13.59 time:2.38 \n",
            "epoch:0 progress:0.241 step:0  loss:5732.8198 gradNorm:19.18 clipValue:13.62 time:2.38 \n",
            "epoch:0 progress:0.243 step:0  loss:5736.0679 gradNorm:19.03 clipValue:13.67 time:2.38 \n",
            "epoch:0 progress:0.245 step:0  loss:5725.6455 gradNorm:20.31 clipValue:13.75 time:2.38 \n",
            "epoch:0 progress:0.247 step:0  loss:5700.1064 gradNorm:21.06 clipValue:13.81 time:6.85 \n",
            "nGT:333.0001 nEst:40981.0001 nCorrect:2.0001\n",
            "f1:9.682432058467195e-05 precision:4.880554391350738e-05 recall:0.006006304502611261\n",
            "f1Frame:0.04361118970450276 precisionFrame:0.02305142101103943 recallFrame:0.40346716417030726\n",
            "mseVelocity:179.15840152900856 mseOF:0.15710160403409978\n",
            "epoch:0 progress:0.249 step:0  loss:5706.4976 gradNorm:22.05 clipValue:14.07 time:2.40 \n",
            "epoch:0 progress:0.251 step:0  loss:5690.7373 gradNorm:22.17 clipValue:14.22 time:2.37 \n",
            "epoch:0 progress:0.253 step:0  loss:5674.4023 gradNorm:23.40 clipValue:14.30 time:2.39 \n",
            "epoch:0 progress:0.255 step:0  loss:5658.0454 gradNorm:24.29 clipValue:14.37 time:2.38 \n",
            "epoch:0 progress:0.257 step:0  loss:5661.7627 gradNorm:24.62 clipValue:14.54 time:2.38 \n",
            "epoch:0 progress:0.259 step:0  loss:5640.0088 gradNorm:25.90 clipValue:14.60 time:2.38 \n",
            "epoch:0 progress:0.261 step:0  loss:5646.9507 gradNorm:24.57 clipValue:14.72 time:2.38 \n",
            "epoch:0 progress:0.263 step:0  loss:5609.8037 gradNorm:27.12 clipValue:14.83 time:2.39 \n",
            "epoch:0 progress:0.265 step:0  loss:5597.3711 gradNorm:29.02 clipValue:14.91 time:2.37 \n",
            "epoch:0 progress:0.267 step:0  loss:5599.3516 gradNorm:28.03 clipValue:15.08 time:2.39 \n",
            "epoch:0 progress:0.270 step:0  loss:5560.8447 gradNorm:31.07 clipValue:15.29 time:2.39 \n",
            "epoch:0 progress:0.272 step:0  loss:5537.7153 gradNorm:31.66 clipValue:15.47 time:2.40 \n",
            "epoch:0 progress:0.274 step:0  loss:5515.6572 gradNorm:33.28 clipValue:15.61 time:2.39 \n",
            "epoch:0 progress:0.276 step:0  loss:5500.8926 gradNorm:34.09 clipValue:15.69 time:2.38 \n",
            "epoch:0 progress:0.278 step:0  loss:5494.1592 gradNorm:34.73 clipValue:15.72 time:2.38 \n",
            "epoch:0 progress:0.280 step:0  loss:5464.0234 gradNorm:39.22 clipValue:16.31 time:2.37 \n",
            "epoch:0 progress:0.282 step:0  loss:5414.5571 gradNorm:39.84 clipValue:16.54 time:2.39 \n",
            "epoch:0 progress:0.284 step:0  loss:5409.7876 gradNorm:41.03 clipValue:16.60 time:2.38 \n",
            "epoch:0 progress:0.286 step:0  loss:5361.5649 gradNorm:44.31 clipValue:16.69 time:2.38 \n",
            "epoch:0 progress:0.288 step:0  loss:5374.0947 gradNorm:43.88 clipValue:16.99 time:2.38 \n",
            "epoch:0 progress:0.290 step:0  loss:5320.9653 gradNorm:47.82 clipValue:17.33 time:2.41 \n",
            "epoch:0 progress:0.292 step:0  loss:5273.6387 gradNorm:52.30 clipValue:17.80 time:2.38 \n",
            "epoch:0 progress:0.294 step:0  loss:5323.2607 gradNorm:54.48 clipValue:18.07 time:2.38 \n",
            "epoch:0 progress:0.296 step:0  loss:5294.0518 gradNorm:51.23 clipValue:18.28 time:2.37 \n",
            "epoch:0 progress:0.298 step:0  loss:5165.9453 gradNorm:58.79 clipValue:19.03 time:2.37 \n",
            "epoch:0 progress:0.300 step:0  loss:5153.7197 gradNorm:60.14 clipValue:19.15 time:2.37 \n",
            "epoch:0 progress:0.302 step:0  loss:5065.2764 gradNorm:65.58 clipValue:19.52 time:2.37 \n",
            "epoch:0 progress:0.305 step:0  loss:5072.6064 gradNorm:67.23 clipValue:19.97 time:2.38 \n",
            "epoch:0 progress:0.307 step:0  loss:4975.8735 gradNorm:72.96 clipValue:20.46 time:2.38 \n",
            "epoch:0 progress:0.309 step:0  loss:4910.4570 gradNorm:79.32 clipValue:21.06 time:2.38 \n",
            "epoch:0 progress:0.311 step:0  loss:4914.8096 gradNorm:77.48 clipValue:21.85 time:2.38 \n",
            "epoch:0 progress:0.313 step:0  loss:4880.9219 gradNorm:82.30 clipValue:22.12 time:2.37 \n",
            "epoch:0 progress:0.315 step:0  loss:4874.3154 gradNorm:84.57 clipValue:22.66 time:2.38 \n",
            "epoch:0 progress:0.317 step:0  loss:4682.4014 gradNorm:93.55 clipValue:23.58 time:2.38 \n",
            "epoch:0 progress:0.319 step:0  loss:4670.8115 gradNorm:101.07 clipValue:24.29 time:2.39 \n",
            "epoch:0 progress:0.321 step:0  loss:4501.3823 gradNorm:107.92 clipValue:24.51 time:2.38 \n",
            "epoch:0 progress:0.323 step:0  loss:4525.7690 gradNorm:107.43 clipValue:24.60 time:2.38 \n",
            "epoch:0 progress:0.325 step:0  loss:4384.6274 gradNorm:114.78 clipValue:25.13 time:2.38 \n",
            "epoch:0 progress:0.327 step:0  loss:4638.0366 gradNorm:139.65 clipValue:26.15 time:2.37 \n",
            "epoch:0 progress:0.329 step:0  loss:4163.2861 gradNorm:128.72 clipValue:27.12 time:6.74 \n",
            "nGT:376.0001 nEst:4.0001 nCorrect:0.0001\n",
            "f1:5.263155124655198e-07 precision:2.4999375015624612e-05 recall:2.6595737607516596e-07\n",
            "f1Frame:1.9700551227333503e-08 precisionFrame:2.8968712949921408e-08 recallFrame:1.4925372911561597e-08\n",
            "mseVelocity:164.6940220228665 mseOF:0.16521786292981955\n",
            "epoch:0 progress:0.331 step:0  loss:4129.0337 gradNorm:132.89 clipValue:27.85 time:2.38 \n",
            "epoch:0 progress:0.333 step:0  loss:3953.3237 gradNorm:142.24 clipValue:28.62 time:2.38 \n",
            "epoch:0 progress:0.335 step:0  loss:3906.7417 gradNorm:144.79 clipValue:29.84 time:2.39 \n",
            "epoch:0 progress:0.337 step:0  loss:3775.3618 gradNorm:150.42 clipValue:31.19 time:2.38 \n",
            "epoch:0 progress:0.340 step:0  loss:3662.1921 gradNorm:157.60 clipValue:31.66 time:2.39 \n",
            "epoch:0 progress:0.342 step:0  loss:3580.8660 gradNorm:163.22 clipValue:32.96 time:2.38 \n",
            "epoch:0 progress:0.344 step:0  loss:3454.0051 gradNorm:167.52 clipValue:33.77 time:2.38 \n",
            "epoch:0 progress:0.346 step:0  loss:3328.3438 gradNorm:170.34 clipValue:34.35 time:2.38 \n",
            "epoch:0 progress:0.348 step:0  loss:3262.4487 gradNorm:180.02 clipValue:35.63 time:2.37 \n",
            "epoch:0 progress:0.350 step:0  loss:3064.7358 gradNorm:179.31 clipValue:39.22 time:2.37 \n",
            "epoch:0 progress:0.352 step:0  loss:2984.2524 gradNorm:182.62 clipValue:39.72 time:2.38 \n",
            "epoch:0 progress:0.354 step:0  loss:2889.2966 gradNorm:182.20 clipValue:39.94 time:2.38 \n",
            "epoch:0 progress:0.356 step:0  loss:2751.7637 gradNorm:187.10 clipValue:40.41 time:2.39 \n",
            "epoch:0 progress:0.358 step:0  loss:2636.9617 gradNorm:191.48 clipValue:41.60 time:2.38 \n",
            "epoch:0 progress:0.360 step:0  loss:2583.4319 gradNorm:200.18 clipValue:43.88 time:2.39 \n",
            "epoch:0 progress:0.362 step:0  loss:2307.8848 gradNorm:190.45 clipValue:44.22 time:2.38 \n",
            "epoch:0 progress:0.364 step:0  loss:2177.2427 gradNorm:186.04 clipValue:46.41 time:2.38 \n",
            "epoch:0 progress:0.366 step:0  loss:2021.6508 gradNorm:183.50 clipValue:49.18 time:2.39 \n",
            "epoch:0 progress:0.368 step:0  loss:1914.9690 gradNorm:181.96 clipValue:51.44 time:2.39 \n",
            "epoch:0 progress:0.370 step:0  loss:1844.4723 gradNorm:181.01 clipValue:52.30 time:2.38 \n",
            "epoch:0 progress:0.372 step:0  loss:1688.6511 gradNorm:176.80 clipValue:54.04 time:2.38 \n",
            "epoch:0 progress:0.374 step:0  loss:1581.0740 gradNorm:164.04 clipValue:57.07 time:2.37 \n",
            "epoch:0 progress:0.377 step:0  loss:1498.3538 gradNorm:156.27 clipValue:59.33 time:2.41 \n",
            "epoch:0 progress:0.379 step:0  loss:1337.0264 gradNorm:153.94 clipValue:61.23 time:2.38 \n",
            "epoch:0 progress:0.381 step:0  loss:1314.8289 gradNorm:161.11 clipValue:65.58 time:2.40 \n",
            "epoch:0 progress:0.383 step:0  loss:1136.6145 gradNorm:145.82 clipValue:66.90 time:2.39 \n",
            "epoch:0 progress:0.385 step:0  loss:1072.7107 gradNorm:144.10 clipValue:70.66 time:2.38 \n",
            "epoch:0 progress:0.387 step:0  loss:945.3620 gradNorm:116.09 clipValue:74.77 time:2.40 \n",
            "epoch:0 progress:0.389 step:0  loss:933.4165 gradNorm:101.95 clipValue:77.85 time:2.38 \n",
            "epoch:0 progress:0.391 step:0  loss:877.4821 gradNorm:90.00 clipValue:79.32 time:2.37 \n",
            "epoch:0 progress:0.393 step:0  loss:785.9293 gradNorm:86.04 clipValue:81.70 time:2.39 \n",
            "epoch:0 progress:0.395 step:0  loss:700.3530 gradNorm:82.67 clipValue:83.66 time:2.39 \n",
            "epoch:0 progress:0.397 step:0  loss:647.0981 gradNorm:68.53 clipValue:83.43 time:2.39 \n",
            "epoch:0 progress:0.399 step:0  loss:672.4202 gradNorm:145.42 clipValue:83.05 time:2.39 \n",
            "epoch:0 progress:0.401 step:0  loss:598.9319 gradNorm:52.06 clipValue:84.57 time:2.38 \n",
            "epoch:0 progress:0.403 step:0  loss:596.2925 gradNorm:44.09 clipValue:84.19 time:2.38 \n",
            "epoch:0 progress:0.405 step:0  loss:557.6379 gradNorm:39.97 clipValue:83.81 time:2.38 \n",
            "epoch:0 progress:0.407 step:0  loss:499.8681 gradNorm:36.16 clipValue:83.43 time:2.38 \n",
            "epoch:0 progress:0.409 step:0  loss:574.0998 gradNorm:38.44 clipValue:83.05 time:2.37 \n",
            "/usr/local/lib/python3.10/dist-packages/mir_eval/transcription.py:167: UserWarning: Estimated notes are empty.\n",
            "  warnings.warn(\"Estimated notes are empty.\")\n",
            "epoch:0 progress:0.412 step:0  loss:603.9049 gradNorm:34.82 clipValue:82.67 time:6.76 \n",
            "nGT:573.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:3.4904001778707934e-07 precision:1.0 recall:1.7452003935077848e-07\n",
            "f1Frame:3.4287672405702984e-08 precisionFrame:1.0 recallFrame:1.7143836496762617e-08\n",
            "mseVelocity:163.4068759324824 mseOF:0.1705092953067875\n",
            "epoch:0 progress:0.414 step:0  loss:567.5965 gradNorm:30.20 clipValue:82.60 time:2.37 \n",
            "epoch:0 progress:0.416 step:0  loss:595.6891 gradNorm:31.32 clipValue:82.52 time:2.38 \n",
            "epoch:0 progress:0.418 step:0  loss:564.3110 gradNorm:24.61 clipValue:82.45 time:2.38 \n",
            "epoch:0 progress:0.420 step:0  loss:655.6118 gradNorm:30.97 clipValue:82.37 time:2.37 \n",
            "epoch:0 progress:0.422 step:0  loss:484.2456 gradNorm:26.32 clipValue:82.30 time:2.39 \n",
            "epoch:0 progress:0.424 step:0  loss:604.6953 gradNorm:34.74 clipValue:81.70 time:2.38 \n",
            "epoch:0 progress:0.426 step:0  loss:570.5392 gradNorm:33.46 clipValue:81.11 time:2.40 \n",
            "epoch:0 progress:0.428 step:0  loss:357.2836 gradNorm:39.41 clipValue:80.51 time:2.38 \n",
            "epoch:0 progress:0.430 step:0  loss:501.0797 gradNorm:25.87 clipValue:79.92 time:2.38 \n",
            "epoch:0 progress:0.432 step:0  loss:596.4818 gradNorm:32.82 clipValue:79.32 time:2.39 \n",
            "epoch:0 progress:0.434 step:0  loss:659.7968 gradNorm:38.63 clipValue:78.96 time:2.39 \n",
            "epoch:0 progress:0.436 step:0  loss:726.4703 gradNorm:47.40 clipValue:78.59 time:2.40 \n",
            "epoch:0 progress:0.438 step:0  loss:491.5875 gradNorm:23.72 clipValue:78.22 time:2.38 \n",
            "epoch:0 progress:0.440 step:0  loss:501.6689 gradNorm:32.90 clipValue:77.85 time:2.38 \n",
            "epoch:0 progress:0.442 step:0  loss:637.3776 gradNorm:36.79 clipValue:77.48 time:2.39 \n",
            "epoch:0 progress:0.444 step:0  loss:668.2043 gradNorm:44.87 clipValue:76.58 time:2.39 \n",
            "epoch:0 progress:0.447 step:0  loss:592.7576 gradNorm:35.77 clipValue:75.67 time:2.38 \n",
            "epoch:0 progress:0.449 step:0  loss:492.4239 gradNorm:30.32 clipValue:74.77 time:2.39 \n",
            "epoch:0 progress:0.451 step:0  loss:544.1367 gradNorm:31.08 clipValue:73.86 time:2.38 \n",
            "epoch:0 progress:0.453 step:0  loss:389.4232 gradNorm:26.12 clipValue:72.96 time:2.38 \n",
            "epoch:0 progress:0.455 step:0  loss:668.7492 gradNorm:40.37 clipValue:72.07 time:2.38 \n",
            "epoch:0 progress:0.457 step:0  loss:637.7211 gradNorm:39.30 clipValue:71.19 time:2.38 \n",
            "epoch:0 progress:0.459 step:0  loss:498.5482 gradNorm:30.32 clipValue:70.30 time:2.39 \n",
            "epoch:0 progress:0.461 step:0  loss:583.1813 gradNorm:33.20 clipValue:69.42 time:2.38 \n",
            "epoch:0 progress:0.463 step:0  loss:648.5880 gradNorm:33.02 clipValue:68.53 time:2.39 \n",
            "epoch:0 progress:0.465 step:0  loss:500.8827 gradNorm:25.19 clipValue:68.27 time:2.38 \n",
            "epoch:0 progress:0.467 step:0  loss:581.9095 gradNorm:29.16 clipValue:68.01 time:2.37 \n",
            "epoch:0 progress:0.469 step:0  loss:550.2982 gradNorm:30.03 clipValue:67.75 time:2.39 \n",
            "epoch:0 progress:0.471 step:0  loss:415.3500 gradNorm:21.54 clipValue:67.49 time:2.39 \n",
            "epoch:0 progress:0.473 step:0  loss:476.8572 gradNorm:28.52 clipValue:67.23 time:2.38 \n",
            "epoch:0 progress:0.475 step:0  loss:570.5904 gradNorm:30.96 clipValue:66.90 time:2.38 \n",
            "epoch:0 progress:0.477 step:0  loss:445.2907 gradNorm:23.03 clipValue:66.57 time:2.39 \n",
            "epoch:0 progress:0.479 step:0  loss:588.1617 gradNorm:25.35 clipValue:66.24 time:2.40 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.481 step:0  loss:546.4784 gradNorm:27.67 clipValue:65.91 time:2.39 \n",
            "epoch:0 progress:0.484 step:0  loss:355.8915 gradNorm:31.92 clipValue:65.58 time:2.39 \n",
            "epoch:0 progress:0.486 step:0  loss:569.7322 gradNorm:27.83 clipValue:64.49 time:2.39 \n",
            "epoch:0 progress:0.488 step:0  loss:501.1171 gradNorm:21.47 clipValue:63.40 time:2.39 \n",
            "epoch:0 progress:0.490 step:0  loss:433.7875 gradNorm:20.43 clipValue:62.32 time:2.37 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.492 step:0  loss:509.1664 gradNorm:31.03 clipValue:61.23 time:2.38 \n",
            "epoch:0 progress:0.494 step:0  loss:440.8578 gradNorm:24.44 clipValue:60.14 time:6.75 \n",
            "nGT:344.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:5.813950108168542e-07 precision:1.0 recall:2.9069758991349133e-07\n",
            "f1Frame:3.6529679030879305e-08 precisionFrame:1.0 recallFrame:1.8264839849044022e-08\n",
            "mseVelocity:145.95980495354507 mseOF:0.17768326850425062\n",
            "epoch:0 progress:0.496 step:0  loss:505.2025 gradNorm:30.22 clipValue:59.87 time:2.38 \n",
            "epoch:0 progress:0.498 step:0  loss:534.2293 gradNorm:28.44 clipValue:59.60 time:2.37 \n",
            "epoch:0 progress:0.500 step:0  loss:401.8718 gradNorm:19.97 clipValue:59.33 time:2.38 \n",
            "epoch:0 progress:0.502 step:0  loss:590.4357 gradNorm:27.14 clipValue:59.06 time:2.37 \n",
            "epoch:0 progress:0.504 step:0  loss:459.8193 gradNorm:26.96 clipValue:58.79 time:2.39 \n",
            "epoch:0 progress:0.506 step:0  loss:502.8877 gradNorm:28.74 clipValue:57.93 time:2.39 \n",
            "epoch:0 progress:0.508 step:0  loss:437.1598 gradNorm:24.71 clipValue:57.07 time:2.40 \n",
            "epoch:0 progress:0.510 step:0  loss:558.0361 gradNorm:25.07 clipValue:56.20 time:2.38 \n",
            "epoch:0 progress:0.512 step:0  loss:564.3595 gradNorm:22.02 clipValue:55.34 time:2.38 \n",
            "epoch:0 progress:0.514 step:0  loss:429.7583 gradNorm:22.78 clipValue:54.48 time:2.38 \n",
            "epoch:0 progress:0.516 step:0  loss:507.6214 gradNorm:22.58 clipValue:54.04 time:2.39 \n",
            "epoch:0 progress:0.519 step:0  loss:521.4002 gradNorm:21.84 clipValue:53.61 time:2.38 \n",
            "epoch:0 progress:0.521 step:0  loss:481.4648 gradNorm:27.04 clipValue:53.17 time:2.38 \n",
            "epoch:0 progress:0.523 step:0  loss:496.6544 gradNorm:24.70 clipValue:52.74 time:2.38 \n",
            "epoch:0 progress:0.525 step:0  loss:389.1501 gradNorm:20.43 clipValue:52.30 time:2.37 \n",
            "epoch:0 progress:0.527 step:0  loss:374.0193 gradNorm:19.94 clipValue:52.25 time:2.39 \n",
            "epoch:0 progress:0.529 step:0  loss:443.3818 gradNorm:18.31 clipValue:52.21 time:2.37 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.531 step:0  loss:469.9998 gradNorm:23.06 clipValue:52.16 time:2.39 \n",
            "epoch:0 progress:0.533 step:0  loss:290.9954 gradNorm:27.19 clipValue:52.11 time:2.39 \n",
            "epoch:0 progress:0.535 step:0  loss:377.0268 gradNorm:19.64 clipValue:52.06 time:2.38 \n",
            "epoch:0 progress:0.537 step:0  loss:504.5740 gradNorm:21.49 clipValue:51.90 time:2.38 \n",
            "epoch:0 progress:0.539 step:0  loss:275.1133 gradNorm:42.27 clipValue:51.73 time:2.37 \n",
            "epoch:0 progress:0.541 step:0  loss:409.9142 gradNorm:21.81 clipValue:51.56 time:2.39 \n",
            "epoch:0 progress:0.543 step:0  loss:420.2082 gradNorm:20.38 clipValue:51.40 time:2.39 \n",
            "epoch:0 progress:0.545 step:0  loss:274.1389 gradNorm:24.36 clipValue:51.23 time:2.38 \n",
            "epoch:0 progress:0.547 step:0  loss:556.9261 gradNorm:27.14 clipValue:50.55 time:2.39 \n",
            "epoch:0 progress:0.549 step:0  loss:475.5925 gradNorm:22.26 clipValue:49.87 time:2.38 \n",
            "epoch:0 progress:0.551 step:0  loss:491.7271 gradNorm:20.23 clipValue:49.18 time:2.40 \n",
            "epoch:0 progress:0.553 step:0  loss:525.5050 gradNorm:23.33 clipValue:48.50 time:2.38 \n",
            "epoch:0 progress:0.556 step:0  loss:334.3854 gradNorm:19.54 clipValue:47.82 time:2.37 \n",
            "epoch:0 progress:0.558 step:0  loss:475.8999 gradNorm:26.08 clipValue:47.74 time:2.38 \n",
            "epoch:0 progress:0.560 step:0  loss:449.8941 gradNorm:20.75 clipValue:47.65 time:2.40 \n",
            "epoch:0 progress:0.562 step:0  loss:396.4812 gradNorm:23.81 clipValue:47.57 time:2.38 \n",
            "epoch:0 progress:0.564 step:0  loss:444.6323 gradNorm:24.98 clipValue:47.49 time:2.38 \n",
            "epoch:0 progress:0.566 step:0  loss:383.0878 gradNorm:21.17 clipValue:47.40 time:2.38 \n",
            "epoch:0 progress:0.568 step:0  loss:401.3604 gradNorm:35.82 clipValue:46.90 time:2.37 \n",
            "epoch:0 progress:0.570 step:0  loss:361.5473 gradNorm:27.88 clipValue:46.39 time:2.40 \n",
            "epoch:0 progress:0.572 step:0  loss:213.5285 gradNorm:25.92 clipValue:45.88 time:2.37 \n",
            "epoch:0 progress:0.574 step:0  loss:454.3034 gradNorm:25.87 clipValue:45.38 time:2.38 \n",
            "epoch:0 progress:0.576 step:0  loss:488.3588 gradNorm:23.79 clipValue:44.87 time:6.79 \n",
            "nGT:640.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:3.124999023437805e-07 precision:1.0 recall:1.5624997558594132e-07\n",
            "f1Frame:3.184206235178913e-08 precisionFrame:1.0 recallFrame:1.5921031429373803e-08\n",
            "mseVelocity:161.33171307316985 mseOF:0.1666101076150894\n",
            "epoch:0 progress:0.578 step:0  loss:388.6772 gradNorm:18.26 clipValue:44.76 time:2.38 \n",
            "epoch:0 progress:0.580 step:0  loss:470.4461 gradNorm:27.86 clipValue:44.64 time:2.39 \n",
            "epoch:0 progress:0.582 step:0  loss:465.8301 gradNorm:29.53 clipValue:44.53 time:2.37 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.584 step:0  loss:454.4567 gradNorm:30.33 clipValue:44.42 time:2.39 \n",
            "epoch:0 progress:0.586 step:0  loss:438.4866 gradNorm:24.83 clipValue:44.31 time:2.40 \n",
            "epoch:0 progress:0.588 step:0  loss:306.6488 gradNorm:18.91 clipValue:44.26 time:2.39 \n",
            "epoch:0 progress:0.591 step:0  loss:392.2814 gradNorm:20.66 clipValue:44.22 time:2.38 \n",
            "epoch:0 progress:0.593 step:0  loss:332.3492 gradNorm:18.73 clipValue:44.18 time:2.37 \n",
            "epoch:0 progress:0.595 step:0  loss:372.5639 gradNorm:21.31 clipValue:44.13 time:2.39 \n",
            "epoch:0 progress:0.597 step:0  loss:269.1888 gradNorm:16.96 clipValue:44.09 time:2.37 \n",
            "epoch:0 progress:0.599 step:0  loss:424.8694 gradNorm:20.81 clipValue:44.05 time:2.37 \n",
            "epoch:0 progress:0.601 step:0  loss:414.3647 gradNorm:19.64 clipValue:44.01 time:2.39 \n",
            "epoch:0 progress:0.603 step:0  loss:324.5540 gradNorm:21.57 clipValue:43.96 time:2.38 \n",
            "epoch:0 progress:0.605 step:0  loss:408.7488 gradNorm:30.55 clipValue:43.92 time:2.39 \n",
            "epoch:0 progress:0.607 step:0  loss:395.2870 gradNorm:25.88 clipValue:43.88 time:2.38 \n",
            "epoch:0 progress:0.609 step:0  loss:364.1130 gradNorm:24.79 clipValue:43.55 time:2.38 \n",
            "epoch:0 progress:0.611 step:0  loss:375.2330 gradNorm:25.38 clipValue:43.23 time:2.39 \n",
            "epoch:0 progress:0.613 step:0  loss:386.6505 gradNorm:24.07 clipValue:42.91 time:2.39 \n",
            "epoch:0 progress:0.615 step:0  loss:284.4444 gradNorm:18.20 clipValue:42.59 time:2.37 \n",
            "epoch:0 progress:0.617 step:0  loss:321.5735 gradNorm:15.11 clipValue:42.27 time:2.40 \n",
            "epoch:0 progress:0.619 step:0  loss:481.9225 gradNorm:34.24 clipValue:42.02 time:2.38 \n",
            "epoch:0 progress:0.621 step:0  loss:458.7027 gradNorm:22.23 clipValue:41.77 time:2.39 \n",
            "epoch:0 progress:0.623 step:0  loss:320.1687 gradNorm:17.81 clipValue:41.52 time:2.38 \n",
            "epoch:0 progress:0.626 step:0  loss:407.4255 gradNorm:21.00 clipValue:41.28 time:2.37 \n",
            "epoch:0 progress:0.628 step:0  loss:433.0833 gradNorm:21.63 clipValue:41.03 time:2.38 \n",
            "epoch:0 progress:0.630 step:0  loss:428.8786 gradNorm:21.06 clipValue:40.90 time:2.38 \n",
            "epoch:0 progress:0.632 step:0  loss:454.8810 gradNorm:24.52 clipValue:40.76 time:2.37 \n",
            "epoch:0 progress:0.634 step:0  loss:413.1242 gradNorm:22.34 clipValue:40.63 time:2.39 \n",
            "epoch:0 progress:0.636 step:0  loss:386.5260 gradNorm:26.13 clipValue:40.50 time:2.38 \n",
            "epoch:0 progress:0.638 step:0  loss:318.7725 gradNorm:22.83 clipValue:40.37 time:2.39 \n",
            "epoch:0 progress:0.640 step:0  loss:346.0406 gradNorm:18.36 clipValue:40.29 time:2.39 \n",
            "epoch:0 progress:0.642 step:0  loss:315.0348 gradNorm:22.33 clipValue:40.22 time:2.38 \n",
            "epoch:0 progress:0.644 step:0  loss:351.5635 gradNorm:27.05 clipValue:40.15 time:2.37 \n",
            "epoch:0 progress:0.646 step:0  loss:491.1203 gradNorm:36.98 clipValue:40.07 time:2.38 \n",
            "epoch:0 progress:0.648 step:0  loss:404.8578 gradNorm:41.29 clipValue:40.00 time:2.39 \n",
            "epoch:0 progress:0.650 step:0  loss:429.2778 gradNorm:34.63 clipValue:40.29 time:2.38 \n",
            "epoch:0 progress:0.652 step:0  loss:485.1987 gradNorm:27.44 clipValue:40.22 time:2.38 \n",
            "epoch:0 progress:0.654 step:0  loss:356.6483 gradNorm:27.34 clipValue:40.15 time:2.42 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.656 step:0  loss:295.8085 gradNorm:33.69 clipValue:40.07 time:2.38 \n",
            "epoch:0 progress:0.658 step:0  loss:329.1615 gradNorm:23.92 clipValue:40.00 time:6.78 \n",
            "nGT:510.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:3.921567089581534e-07 precision:1.0 recall:1.9607839292580533e-07\n",
            "f1Frame:3.627788731079676e-08 precisionFrame:1.0 recallFrame:1.8138943984419663e-08\n",
            "mseVelocity:232.30257393576983 mseOF:0.16888081848212352\n",
            "epoch:0 progress:0.660 step:0  loss:463.9445 gradNorm:33.42 clipValue:39.99 time:2.38 \n",
            "epoch:0 progress:0.663 step:0  loss:385.0444 gradNorm:18.50 clipValue:39.99 time:2.39 \n",
            "epoch:0 progress:0.665 step:0  loss:359.3764 gradNorm:31.37 clipValue:39.98 time:2.39 \n",
            "epoch:0 progress:0.667 step:0  loss:429.3966 gradNorm:26.04 clipValue:39.97 time:2.38 \n",
            "epoch:0 progress:0.669 step:0  loss:470.7025 gradNorm:21.34 clipValue:39.97 time:2.39 \n",
            "epoch:0 progress:0.671 step:0  loss:372.0820 gradNorm:19.11 clipValue:39.94 time:2.39 \n",
            "epoch:0 progress:0.673 step:0  loss:288.0783 gradNorm:26.47 clipValue:39.92 time:2.37 \n",
            "epoch:0 progress:0.675 step:0  loss:361.2893 gradNorm:23.34 clipValue:39.89 time:2.38 \n",
            "epoch:0 progress:0.677 step:0  loss:460.2999 gradNorm:23.07 clipValue:39.87 time:2.37 \n",
            "epoch:0 progress:0.679 step:0  loss:392.9208 gradNorm:25.33 clipValue:39.84 time:2.39 \n",
            "epoch:0 progress:0.681 step:0  loss:274.5813 gradNorm:25.59 clipValue:39.76 time:2.40 \n",
            "epoch:0 progress:0.683 step:0  loss:372.4494 gradNorm:21.77 clipValue:39.67 time:2.40 \n",
            "epoch:0 progress:0.685 step:0  loss:264.7272 gradNorm:20.58 clipValue:39.58 time:2.41 \n",
            "epoch:0 progress:0.687 step:0  loss:336.8112 gradNorm:25.51 clipValue:39.50 time:2.43 \n",
            "epoch:0 progress:0.689 step:0  loss:403.2641 gradNorm:22.50 clipValue:39.41 time:2.39 \n",
            "epoch:0 progress:0.691 step:0  loss:367.0974 gradNorm:27.77 clipValue:39.39 time:2.37 \n",
            "epoch:0 progress:0.693 step:0  loss:285.0388 gradNorm:29.05 clipValue:39.37 time:2.38 \n",
            "epoch:0 progress:0.695 step:0  loss:245.5352 gradNorm:29.10 clipValue:39.34 time:2.40 \n",
            "epoch:0 progress:0.698 step:0  loss:407.9453 gradNorm:26.58 clipValue:39.32 time:2.38 \n",
            "epoch:0 progress:0.700 step:0  loss:309.0679 gradNorm:30.81 clipValue:39.30 time:2.38 \n",
            "epoch:0 progress:0.702 step:0  loss:403.8546 gradNorm:27.36 clipValue:39.28 time:2.38 \n",
            "epoch:0 progress:0.704 step:0  loss:288.9148 gradNorm:32.26 clipValue:39.27 time:2.38 \n",
            "epoch:0 progress:0.706 step:0  loss:352.2241 gradNorm:30.31 clipValue:39.25 time:2.38 \n",
            "epoch:0 progress:0.708 step:0  loss:301.1863 gradNorm:28.17 clipValue:39.24 time:2.38 \n",
            "epoch:0 progress:0.710 step:0  loss:270.1218 gradNorm:15.95 clipValue:39.22 time:2.40 \n",
            "epoch:0 progress:0.712 step:0  loss:359.6417 gradNorm:29.62 clipValue:39.10 time:2.38 \n",
            "epoch:0 progress:0.714 step:0  loss:468.0490 gradNorm:28.84 clipValue:38.98 time:2.39 \n",
            "epoch:0 progress:0.716 step:0  loss:296.9690 gradNorm:29.50 clipValue:38.87 time:2.39 \n",
            "epoch:0 progress:0.718 step:0  loss:457.5054 gradNorm:32.53 clipValue:38.75 time:2.38 \n",
            "epoch:0 progress:0.720 step:0  loss:250.8130 gradNorm:26.52 clipValue:38.63 time:2.40 \n",
            "epoch:0 progress:0.722 step:0  loss:282.6681 gradNorm:17.69 clipValue:38.59 time:2.38 \n",
            "epoch:0 progress:0.724 step:0  loss:359.2292 gradNorm:20.74 clipValue:38.55 time:2.37 \n",
            "epoch:0 progress:0.726 step:0  loss:388.0612 gradNorm:38.56 clipValue:38.51 time:2.38 \n",
            "epoch:0 progress:0.728 step:0  loss:331.7702 gradNorm:25.72 clipValue:38.57 time:2.39 \n",
            "epoch:0 progress:0.730 step:0  loss:317.6827 gradNorm:18.30 clipValue:38.56 time:2.37 \n",
            "epoch:0 progress:0.733 step:0  loss:288.5011 gradNorm:30.14 clipValue:38.53 time:2.38 \n",
            "epoch:0 progress:0.735 step:0  loss:419.8055 gradNorm:40.39 clipValue:38.51 time:2.38 \n",
            "epoch:0 progress:0.737 step:0  loss:446.3224 gradNorm:27.54 clipValue:38.59 time:2.37 \n",
            "epoch:0 progress:0.739 step:0  loss:330.0529 gradNorm:28.26 clipValue:38.57 time:2.37 \n",
            "epoch:0 progress:0.741 step:0  loss:339.4696 gradNorm:28.43 clipValue:38.56 time:6.76 \n",
            "nGT:465.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:4.301073418893153e-07 precision:1.0 recall:2.15053717192749e-07\n",
            "f1Frame:3.2467531413391845e-08 precisionFrame:1.0 recallFrame:1.6233765970231073e-08\n",
            "mseVelocity:155.15900561096655 mseOF:0.17503486068533744\n",
            "epoch:0 progress:0.743 step:0  loss:325.9793 gradNorm:33.21 clipValue:38.53 time:2.38 \n",
            "epoch:0 progress:0.745 step:0  loss:319.2809 gradNorm:28.96 clipValue:38.51 time:2.38 \n",
            "epoch:0 progress:0.747 step:0  loss:301.7240 gradNorm:35.02 clipValue:38.49 time:2.38 \n",
            "epoch:0 progress:0.749 step:0  loss:396.1407 gradNorm:33.52 clipValue:38.46 time:2.40 \n",
            "epoch:0 progress:0.751 step:0  loss:337.0496 gradNorm:31.11 clipValue:38.44 time:2.37 \n",
            "epoch:0 progress:0.753 step:0  loss:296.2224 gradNorm:35.78 clipValue:38.15 time:2.39 \n",
            "epoch:0 progress:0.755 step:0  loss:345.5922 gradNorm:25.75 clipValue:37.86 time:2.38 \n",
            "epoch:0 progress:0.757 step:0  loss:335.0480 gradNorm:30.76 clipValue:37.57 time:2.39 \n",
            "epoch:0 progress:0.759 step:0  loss:452.1456 gradNorm:36.32 clipValue:37.27 time:2.38 \n",
            "epoch:0 progress:0.761 step:0  loss:371.9919 gradNorm:33.62 clipValue:36.98 time:2.37 \n",
            "epoch:0 progress:0.763 step:0  loss:384.3507 gradNorm:30.00 clipValue:36.95 time:2.38 \n",
            "epoch:0 progress:0.765 step:0  loss:302.4860 gradNorm:32.98 clipValue:36.91 time:2.39 \n",
            "epoch:0 progress:0.767 step:0  loss:325.4370 gradNorm:33.91 clipValue:36.87 time:2.39 \n",
            "epoch:0 progress:0.770 step:0  loss:285.7064 gradNorm:20.00 clipValue:36.83 time:2.38 \n",
            "epoch:0 progress:0.772 step:0  loss:329.2923 gradNorm:24.72 clipValue:36.79 time:2.39 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.774 step:0  loss:336.8904 gradNorm:39.16 clipValue:36.70 time:2.38 \n",
            "epoch:0 progress:0.776 step:0  loss:355.1974 gradNorm:30.71 clipValue:36.91 time:2.39 \n",
            "epoch:0 progress:0.778 step:0  loss:451.4940 gradNorm:44.45 clipValue:36.87 time:2.39 \n",
            "epoch:0 progress:0.780 step:0  loss:338.9965 gradNorm:25.25 clipValue:37.27 time:2.38 \n",
            "epoch:0 progress:0.782 step:0  loss:219.1824 gradNorm:30.38 clipValue:36.98 time:2.40 \n",
            "epoch:0 progress:0.784 step:0  loss:370.1865 gradNorm:40.81 clipValue:36.95 time:2.38 \n",
            "epoch:0 progress:0.786 step:0  loss:332.2153 gradNorm:26.66 clipValue:37.86 time:2.39 \n",
            "epoch:0 progress:0.788 step:0  loss:369.2131 gradNorm:32.08 clipValue:37.57 time:2.39 \n",
            "epoch:0 progress:0.790 step:0  loss:257.9355 gradNorm:31.25 clipValue:37.27 time:2.39 \n",
            "epoch:0 progress:0.792 step:0  loss:239.1216 gradNorm:35.69 clipValue:36.98 time:2.38 \n",
            "epoch:0 progress:0.794 step:0  loss:375.3418 gradNorm:43.15 clipValue:36.95 time:2.37 \n",
            "epoch:0 progress:0.796 step:0  loss:316.4929 gradNorm:43.58 clipValue:37.86 time:2.38 \n",
            "epoch:0 progress:0.798 step:0  loss:233.5496 gradNorm:29.34 clipValue:38.49 time:2.40 \n",
            "epoch:0 progress:0.800 step:0  loss:325.5148 gradNorm:29.69 clipValue:38.46 time:2.38 \n",
            "epoch:0 progress:0.802 step:0  loss:377.9635 gradNorm:37.03 clipValue:38.44 time:2.37 \n",
            "epoch:0 progress:0.805 step:0  loss:235.4815 gradNorm:35.86 clipValue:38.16 time:2.38 \n",
            "epoch:0 progress:0.807 step:0  loss:338.5276 gradNorm:43.26 clipValue:37.88 time:2.40 \n",
            "epoch:0 progress:0.809 step:0  loss:338.9503 gradNorm:34.70 clipValue:38.49 time:2.39 \n",
            "epoch:0 progress:0.811 step:0  loss:351.8026 gradNorm:20.90 clipValue:38.46 time:2.38 \n",
            "epoch:0 progress:0.813 step:0  loss:365.1595 gradNorm:33.16 clipValue:38.44 time:2.38 \n",
            "epoch:0 progress:0.815 step:0  loss:344.9463 gradNorm:35.71 clipValue:38.16 time:2.38 \n",
            "epoch:0 progress:0.817 step:0  loss:312.0411 gradNorm:33.80 clipValue:37.88 time:2.39 \n",
            "epoch:0 progress:0.819 step:0  loss:230.3835 gradNorm:30.70 clipValue:37.59 time:2.39 \n",
            "epoch:0 progress:0.821 step:0  loss:343.1203 gradNorm:34.54 clipValue:37.31 time:2.39 \n",
            "saved\n",
            "epoch:0 progress:0.823 step:0  loss:357.2553 gradNorm:30.57 clipValue:37.03 time:6.86 \n",
            "nGT:423.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:4.7281301521843263e-07 precision:1.0 recall:2.3640656349726635e-07\n",
            "f1Frame:3.3726811678691e-08 precisionFrame:1.0 recallFrame:1.6863406123719965e-08\n",
            "mseVelocity:166.6693607164632 mseOF:0.1624442724279387\n",
            "epoch:0 progress:0.825 step:0  loss:315.7591 gradNorm:24.84 clipValue:37.02 time:2.38 \n",
            "epoch:0 progress:0.827 step:0  loss:403.2678 gradNorm:34.41 clipValue:37.01 time:2.39 \n",
            "epoch:0 progress:0.829 step:0  loss:315.8339 gradNorm:34.02 clipValue:37.00 time:2.43 \n",
            "epoch:0 progress:0.831 step:0  loss:266.5894 gradNorm:30.67 clipValue:36.99 time:2.39 \n",
            "epoch:0 progress:0.833 step:0  loss:323.0775 gradNorm:24.13 clipValue:36.98 time:2.38 \n",
            "epoch:0 progress:0.835 step:0  loss:298.3284 gradNorm:29.27 clipValue:36.95 time:2.37 \n",
            "epoch:0 progress:0.837 step:0  loss:297.9675 gradNorm:29.29 clipValue:36.91 time:2.37 \n",
            "epoch:0 progress:0.840 step:0  loss:354.0656 gradNorm:25.88 clipValue:36.87 time:2.37 \n",
            "epoch:0 progress:0.842 step:0  loss:318.9027 gradNorm:34.51 clipValue:36.83 time:2.39 \n",
            "epoch:0 progress:0.844 step:0  loss:232.8340 gradNorm:29.20 clipValue:36.79 time:2.37 \n",
            "epoch:0 progress:0.846 step:0  loss:210.0417 gradNorm:18.86 clipValue:36.70 time:2.38 \n",
            "epoch:0 progress:0.848 step:0  loss:337.2357 gradNorm:32.39 clipValue:36.60 time:2.38 \n",
            "epoch:0 progress:0.850 step:0  loss:269.0215 gradNorm:21.18 clipValue:36.51 time:2.40 \n",
            "epoch:0 progress:0.852 step:0  loss:331.9927 gradNorm:24.72 clipValue:36.41 time:2.38 \n",
            "epoch:0 progress:0.854 step:0  loss:348.7624 gradNorm:20.16 clipValue:36.32 time:2.38 \n",
            "epoch:0 progress:0.856 step:0  loss:272.5818 gradNorm:28.46 clipValue:36.29 time:2.38 \n",
            "epoch:0 progress:0.858 step:0  loss:320.1966 gradNorm:23.09 clipValue:36.26 time:2.38 \n",
            "epoch:0 progress:0.860 step:0  loss:283.8092 gradNorm:22.70 clipValue:36.22 time:2.38 \n",
            "epoch:0 progress:0.862 step:0  loss:313.6153 gradNorm:40.88 clipValue:36.19 time:2.38 \n",
            "epoch:0 progress:0.864 step:0  loss:193.6660 gradNorm:25.96 clipValue:36.32 time:2.39 \n",
            "epoch:0 progress:0.866 step:0  loss:257.8155 gradNorm:28.97 clipValue:36.29 time:2.40 \n",
            "epoch:0 progress:0.868 step:0  loss:270.1167 gradNorm:31.78 clipValue:36.26 time:2.38 \n",
            "epoch:0 progress:0.870 step:0  loss:259.1042 gradNorm:23.61 clipValue:36.22 time:2.38 \n",
            "epoch:0 progress:0.872 step:0  loss:334.7885 gradNorm:29.73 clipValue:36.19 time:2.37 \n",
            "epoch:0 progress:0.874 step:0  loss:316.0622 gradNorm:37.20 clipValue:36.16 time:2.38 \n",
            "epoch:0 progress:0.877 step:0  loss:250.9380 gradNorm:29.59 clipValue:36.29 time:2.39 \n",
            "epoch:0 progress:0.879 step:0  loss:259.0467 gradNorm:31.69 clipValue:36.26 time:2.38 \n",
            "epoch:0 progress:0.881 step:0  loss:306.2772 gradNorm:22.67 clipValue:36.22 time:2.39 \n",
            "epoch:0 progress:0.883 step:0  loss:210.4942 gradNorm:38.06 clipValue:36.19 time:2.40 \n",
            "epoch:0 progress:0.885 step:0  loss:218.1929 gradNorm:32.95 clipValue:36.32 time:2.38 \n",
            "epoch:0 progress:0.887 step:0  loss:326.5467 gradNorm:37.26 clipValue:36.29 time:2.38 \n",
            "epoch:0 progress:0.889 step:0  loss:365.7679 gradNorm:37.67 clipValue:36.60 time:2.37 \n",
            "epoch:0 progress:0.891 step:0  loss:305.7232 gradNorm:26.37 clipValue:36.87 time:2.38 \n",
            "epoch:0 progress:0.893 step:0  loss:211.9210 gradNorm:32.91 clipValue:36.83 time:2.38 \n",
            "epoch:0 progress:0.895 step:0  loss:277.2068 gradNorm:36.35 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.897 step:0  loss:262.0237 gradNorm:30.20 clipValue:36.71 time:2.38 \n",
            "epoch:0 progress:0.899 step:0  loss:334.9228 gradNorm:34.67 clipValue:36.62 time:2.38 \n",
            "epoch:0 progress:0.901 step:0  loss:142.5998 gradNorm:21.74 clipValue:36.53 time:2.37 \n",
            "epoch:0 progress:0.903 step:0  loss:283.7876 gradNorm:33.14 clipValue:36.44 time:2.39 \n",
            "/usr/local/lib/python3.10/dist-packages/mir_eval/transcription.py:165: UserWarning: Reference notes are empty.\n",
            "  warnings.warn(\"Reference notes are empty.\")\n",
            "epoch:0 progress:0.905 step:0  loss:204.0356 gradNorm:24.80 clipValue:36.35 time:6.80 \n",
            "nGT:279.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:7.168453642685562e-07 precision:1.0 recall:3.584228106011432e-07\n",
            "f1Frame:4.6707144011810176e-08 precisionFrame:1.0 recallFrame:2.335357255129443e-08\n",
            "mseVelocity:126.37032040938338 mseOF:0.16848539650833544\n",
            "epoch:0 progress:0.907 step:0  loss:342.9373 gradNorm:36.78 clipValue:36.35 time:2.40 \n",
            "epoch:0 progress:0.909 step:0  loss:326.4023 gradNorm:37.29 clipValue:36.61 time:2.39 \n",
            "epoch:0 progress:0.912 step:0  loss:383.8881 gradNorm:38.31 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.914 step:0  loss:201.0820 gradNorm:24.16 clipValue:36.83 time:2.38 \n",
            "epoch:0 progress:0.916 step:0  loss:318.8451 gradNorm:28.66 clipValue:36.79 time:2.40 \n",
            "epoch:0 progress:0.918 step:0  loss:242.7053 gradNorm:33.85 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.920 step:0  loss:348.2675 gradNorm:33.78 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.922 step:0  loss:222.5031 gradNorm:25.50 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.924 step:0  loss:200.9626 gradNorm:29.25 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.926 step:0  loss:322.5364 gradNorm:36.10 clipValue:36.78 time:2.37 \n",
            "epoch:0 progress:0.928 step:0  loss:212.6798 gradNorm:32.76 clipValue:36.70 time:2.40 \n",
            "epoch:0 progress:0.930 step:0  loss:294.0172 gradNorm:30.77 clipValue:36.61 time:2.38 \n",
            "epoch:0 progress:0.932 step:0  loss:295.5810 gradNorm:19.43 clipValue:36.52 time:2.38 \n",
            "epoch:0 progress:0.934 step:0  loss:258.3369 gradNorm:23.47 clipValue:36.44 time:2.38 \n",
            "epoch:0 progress:0.936 step:0  loss:256.6023 gradNorm:37.10 clipValue:36.35 time:2.38 \n",
            "epoch:0 progress:0.938 step:0  loss:277.4467 gradNorm:33.87 clipValue:36.70 time:2.39 \n",
            "epoch:0 progress:0.940 step:0  loss:305.7121 gradNorm:27.85 clipValue:36.61 time:2.37 \n",
            "epoch:0 progress:0.942 step:0  loss:295.3785 gradNorm:28.50 clipValue:36.52 time:2.39 \n",
            "epoch:0 progress:0.944 step:0  loss:237.8056 gradNorm:23.98 clipValue:36.44 time:2.38 \n",
            "epoch:0 progress:0.947 step:0  loss:278.1225 gradNorm:36.69 clipValue:36.35 time:2.38 \n",
            "epoch:0 progress:0.949 step:0  loss:334.0276 gradNorm:29.59 clipValue:36.62 time:2.38 \n",
            "epoch:0 progress:0.951 step:0  loss:254.5747 gradNorm:28.85 clipValue:36.56 time:2.38 \n",
            "epoch:0 progress:0.953 step:0  loss:243.6095 gradNorm:34.84 clipValue:36.49 time:2.38 \n",
            "epoch:0 progress:0.955 step:0  loss:351.1135 gradNorm:39.03 clipValue:36.42 time:2.38 \n",
            "epoch:0 progress:0.957 step:0  loss:279.1964 gradNorm:26.23 clipValue:36.69 time:2.38 \n",
            "epoch:0 progress:0.959 step:0  loss:317.1011 gradNorm:32.36 clipValue:36.62 time:2.39 \n",
            "epoch:0 progress:0.961 step:0  loss:256.7834 gradNorm:39.85 clipValue:36.56 time:2.39 \n",
            "epoch:0 progress:0.963 step:0  loss:242.0597 gradNorm:31.02 clipValue:36.73 time:2.39 \n",
            "epoch:0 progress:0.965 step:0  loss:248.6637 gradNorm:26.75 clipValue:36.71 time:2.39 \n",
            "epoch:0 progress:0.967 step:0  loss:254.6673 gradNorm:40.16 clipValue:36.69 time:2.39 \n",
            "epoch:0 progress:0.969 step:0  loss:204.2439 gradNorm:38.74 clipValue:36.77 time:2.39 \n",
            "epoch:0 progress:0.971 step:0  loss:273.6887 gradNorm:33.85 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.973 step:0  loss:268.5191 gradNorm:30.42 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.975 step:0  loss:267.1999 gradNorm:34.33 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.977 step:0  loss:348.9727 gradNorm:34.10 clipValue:36.78 time:2.38 \n",
            "epoch:0 progress:0.979 step:0  loss:237.6432 gradNorm:35.42 clipValue:36.77 time:2.40 \n",
            "epoch:0 progress:0.981 step:0  loss:177.2372 gradNorm:17.81 clipValue:36.75 time:2.37 \n",
            "epoch:0 progress:0.984 step:0  loss:255.5343 gradNorm:41.80 clipValue:36.73 time:2.38 \n",
            "epoch:0 progress:0.986 step:0  loss:250.9165 gradNorm:40.04 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.988 step:0  loss:190.6760 gradNorm:31.51 clipValue:36.79 time:6.78 \n",
            "nGT:433.0001 nEst:0.0001 nCorrect:0.0001\n",
            "f1:4.6189355108842916e-07 precision:1.0 recall:2.3094682888064e-07\n",
            "f1Frame:4.9529467581502345e-08 precisionFrame:1.0 recallFrame:2.476473440404323e-08\n",
            "mseVelocity:158.79961690540026 mseOF:0.15644452224009664\n",
            "epoch:0 progress:0.990 step:0  loss:228.1561 gradNorm:33.32 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.992 step:0  loss:279.6573 gradNorm:39.13 clipValue:36.79 time:2.38 \n",
            "epoch:0 progress:0.994 step:0  loss:205.7838 gradNorm:22.23 clipValue:36.87 time:2.39 \n",
            "epoch:0 progress:0.996 step:0  loss:283.3699 gradNorm:23.50 clipValue:36.83 time:2.38 \n",
            "epoch:0 progress:0.998 step:0  loss:299.3911 gradNorm:27.31 clipValue:36.79 time:2.00 \n",
            "Validating...\n",
            "{'logProb': -4139.73046875, 'length': 882000, 'nGT': 327, 'nEst': 0, 'nCorrect': 0.0} progress:0.00\n",
            "{'logProb': -4807.62060546875, 'length': 882000, 'nGT': 322, 'nEst': 0, 'nCorrect': 0.0} progress:0.01\n",
            "{'logProb': -4063.22998046875, 'length': 882000, 'nGT': 498, 'nEst': 0, 'nCorrect': 0.0} progress:0.03\n",
            "{'logProb': -4686.63330078125, 'length': 882000, 'nGT': 348, 'nEst': 0, 'nCorrect': 0.0} progress:0.04\n",
            "{'logProb': -2747.60546875, 'length': 882000, 'nGT': 222, 'nEst': 0, 'nCorrect': 0.0} progress:0.06\n",
            "{'logProb': -5369.1953125, 'length': 882000, 'nGT': 420, 'nEst': 0, 'nCorrect': 0.0} progress:0.07\n",
            "{'logProb': -5958.0146484375, 'length': 882000, 'nGT': 627, 'nEst': 0, 'nCorrect': 0.0} progress:0.08\n",
            "{'logProb': -5502.966796875, 'length': 882000, 'nGT': 525, 'nEst': 0, 'nCorrect': 0.0} progress:0.10\n",
            "{'logProb': -5875.513671875, 'length': 882000, 'nGT': 571, 'nEst': 0, 'nCorrect': 0.0} progress:0.11\n",
            "{'logProb': -4194.015625, 'length': 882000, 'nGT': 245, 'nEst': 0, 'nCorrect': 0.0} progress:0.13\n",
            "{'logProb': -5623.1513671875, 'length': 882000, 'nGT': 388, 'nEst': 0, 'nCorrect': 0.0} progress:0.14\n",
            "{'logProb': -4235.84375, 'length': 882000, 'nGT': 380, 'nEst': 0, 'nCorrect': 0.0} progress:0.15\n",
            "{'logProb': -6253.0595703125, 'length': 882000, 'nGT': 462, 'nEst': 0, 'nCorrect': 0.0} progress:0.17\n",
            "{'logProb': -2419.559326171875, 'length': 882000, 'nGT': 201, 'nEst': 0, 'nCorrect': 0.0} progress:0.18\n",
            "{'logProb': -4369.9990234375, 'length': 882000, 'nGT': 334, 'nEst': 0, 'nCorrect': 0.0} progress:0.20\n",
            "{'logProb': -4854.78076171875, 'length': 882000, 'nGT': 432, 'nEst': 0, 'nCorrect': 0.0} progress:0.21\n",
            "{'logProb': -4354.86572265625, 'length': 882000, 'nGT': 281, 'nEst': 0, 'nCorrect': 0.0} progress:0.23\n",
            "{'logProb': -5813.748046875, 'length': 882000, 'nGT': 734, 'nEst': 0, 'nCorrect': 0.0} progress:0.24\n",
            "{'logProb': -4044.203857421875, 'length': 882000, 'nGT': 428, 'nEst': 0, 'nCorrect': 0.0} progress:0.25\n",
            "{'logProb': -5321.515625, 'length': 882000, 'nGT': 545, 'nEst': 0, 'nCorrect': 0.0} progress:0.27\n",
            "{'logProb': -5106.0908203125, 'length': 882000, 'nGT': 484, 'nEst': 0, 'nCorrect': 0.0} progress:0.28\n",
            "{'logProb': -4826.865234375, 'length': 882000, 'nGT': 499, 'nEst': 0, 'nCorrect': 0.0} progress:0.30\n",
            "{'logProb': -5086.88134765625, 'length': 882000, 'nGT': 413, 'nEst': 0, 'nCorrect': 0.0} progress:0.31\n",
            "{'logProb': -5322.7138671875, 'length': 882000, 'nGT': 517, 'nEst': 0, 'nCorrect': 0.0} progress:0.32\n",
            "{'logProb': -4171.78076171875, 'length': 882000, 'nGT': 330, 'nEst': 0, 'nCorrect': 0.0} progress:0.34\n",
            "{'logProb': -4832.9716796875, 'length': 882000, 'nGT': 415, 'nEst': 0, 'nCorrect': 0.0} progress:0.35\n",
            "{'logProb': -5316.7744140625, 'length': 882000, 'nGT': 406, 'nEst': 0, 'nCorrect': 0.0} progress:0.37\n",
            "{'logProb': -4773.2373046875, 'length': 882000, 'nGT': 416, 'nEst': 0, 'nCorrect': 0.0} progress:0.38\n",
            "{'logProb': -5745.611328125, 'length': 882000, 'nGT': 418, 'nEst': 0, 'nCorrect': 0.0} progress:0.39\n",
            "{'logProb': -3018.6806640625, 'length': 882000, 'nGT': 265, 'nEst': 0, 'nCorrect': 0.0} progress:0.41\n",
            "{'logProb': -5634.005859375, 'length': 882000, 'nGT': 409, 'nEst': 0, 'nCorrect': 0.0} progress:0.42\n",
            "{'logProb': -5239.0654296875, 'length': 882000, 'nGT': 424, 'nEst': 0, 'nCorrect': 0.0} progress:0.44\n",
            "{'logProb': -3096.56201171875, 'length': 882000, 'nGT': 353, 'nEst': 0, 'nCorrect': 0.0} progress:0.45\n",
            "{'logProb': -5405.1455078125, 'length': 882000, 'nGT': 398, 'nEst': 0, 'nCorrect': 0.0} progress:0.46\n",
            "{'logProb': -5195.48681640625, 'length': 882000, 'nGT': 481, 'nEst': 0, 'nCorrect': 0.0} progress:0.48\n",
            "{'logProb': -3911.725830078125, 'length': 882000, 'nGT': 404, 'nEst': 0, 'nCorrect': 0.0} progress:0.49\n",
            "{'logProb': -4736.9013671875, 'length': 882000, 'nGT': 279, 'nEst': 0, 'nCorrect': 0.0} progress:0.51\n",
            "{'logProb': -5311.798828125, 'length': 882000, 'nGT': 343, 'nEst': 0, 'nCorrect': 0.0} progress:0.52\n",
            "{'logProb': -3974.130615234375, 'length': 882000, 'nGT': 288, 'nEst': 0, 'nCorrect': 0.0} progress:0.54\n",
            "{'logProb': -5686.94921875, 'length': 882000, 'nGT': 433, 'nEst': 0, 'nCorrect': 0.0} progress:0.55\n",
            "{'logProb': -3968.337890625, 'length': 882000, 'nGT': 361, 'nEst': 0, 'nCorrect': 0.0} progress:0.56\n",
            "{'logProb': -5696.5380859375, 'length': 882000, 'nGT': 454, 'nEst': 0, 'nCorrect': 0.0} progress:0.58\n",
            "{'logProb': -3774.177001953125, 'length': 882000, 'nGT': 409, 'nEst': 0, 'nCorrect': 0.0} progress:0.59\n",
            "{'logProb': -3976.81982421875, 'length': 882000, 'nGT': 310, 'nEst': 0, 'nCorrect': 0.0} progress:0.61\n",
            "{'logProb': -4375.912109375, 'length': 882000, 'nGT': 424, 'nEst': 0, 'nCorrect': 0.0} progress:0.62\n",
            "{'logProb': -5437.13916015625, 'length': 882000, 'nGT': 691, 'nEst': 0, 'nCorrect': 0.0} progress:0.63\n",
            "{'logProb': -5507.74267578125, 'length': 882000, 'nGT': 577, 'nEst': 0, 'nCorrect': 0.0} progress:0.65\n",
            "{'logProb': -4120.3349609375, 'length': 882000, 'nGT': 362, 'nEst': 0, 'nCorrect': 0.0} progress:0.66\n",
            "{'logProb': -5206.66796875, 'length': 882000, 'nGT': 445, 'nEst': 0, 'nCorrect': 0.0} progress:0.68\n",
            "{'logProb': -4318.74951171875, 'length': 882000, 'nGT': 305, 'nEst': 0, 'nCorrect': 0.0} progress:0.69\n",
            "{'logProb': -4959.46630859375, 'length': 882000, 'nGT': 392, 'nEst': 0, 'nCorrect': 0.0} progress:0.70\n",
            "{'logProb': -4753.10498046875, 'length': 882000, 'nGT': 635, 'nEst': 0, 'nCorrect': 0.0} progress:0.72\n",
            "{'logProb': -4841.33447265625, 'length': 882000, 'nGT': 390, 'nEst': 0, 'nCorrect': 0.0} progress:0.73\n",
            "{'logProb': -5653.3076171875, 'length': 882000, 'nGT': 417, 'nEst': 0, 'nCorrect': 0.0} progress:0.75\n",
            "{'logProb': -5010.685546875, 'length': 882000, 'nGT': 284, 'nEst': 0, 'nCorrect': 0.0} progress:0.76\n",
            "{'logProb': -6303.06201171875, 'length': 882000, 'nGT': 367, 'nEst': 0, 'nCorrect': 0.0} progress:0.77\n",
            "{'logProb': -5394.3125, 'length': 882000, 'nGT': 437, 'nEst': 0, 'nCorrect': 0.0} progress:0.79\n",
            "{'logProb': -5085.5712890625, 'length': 882000, 'nGT': 583, 'nEst': 0, 'nCorrect': 0.0} progress:0.80\n",
            "{'logProb': -4640.59375, 'length': 882000, 'nGT': 404, 'nEst': 0, 'nCorrect': 0.0} progress:0.82\n",
            "{'logProb': -3219.90283203125, 'length': 882000, 'nGT': 251, 'nEst': 0, 'nCorrect': 0.0} progress:0.83\n",
            "{'logProb': -5121.3330078125, 'length': 882000, 'nGT': 627, 'nEst': 0, 'nCorrect': 0.0} progress:0.85\n",
            "{'logProb': -5532.0556640625, 'length': 882000, 'nGT': 566, 'nEst': 0, 'nCorrect': 0.0} progress:0.86\n",
            "{'logProb': -4604.591796875, 'length': 882000, 'nGT': 251, 'nEst': 0, 'nCorrect': 0.0} progress:0.87\n",
            "{'logProb': -4955.69677734375, 'length': 882000, 'nGT': 462, 'nEst': 0, 'nCorrect': 0.0} progress:0.89\n",
            "{'logProb': -6520.6005859375, 'length': 882000, 'nGT': 428, 'nEst': 0, 'nCorrect': 0.0} progress:0.90\n",
            "{'logProb': -5480.5107421875, 'length': 882000, 'nGT': 397, 'nEst': 0, 'nCorrect': 0.0} progress:0.92\n",
            "{'logProb': -5822.66259765625, 'length': 882000, 'nGT': 454, 'nEst': 0, 'nCorrect': 0.0} progress:0.93\n",
            "{'logProb': -5633.9296875, 'length': 882000, 'nGT': 446, 'nEst': 0, 'nCorrect': 0.0} progress:0.94\n",
            "{'logProb': -5598.69287109375, 'length': 882000, 'nGT': 482, 'nEst': 0, 'nCorrect': 0.0} progress:0.96\n",
            "{'logProb': -4958.9150390625, 'length': 882000, 'nGT': 315, 'nEst': 0, 'nCorrect': 0.0} progress:0.97\n",
            "{'logProb': -5453.91943359375, 'length': 882000, 'nGT': 400, 'nEst': 0, 'nCorrect': 0.0} progress:0.99\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/train.py\", line 392, in <module>\n",
            "    train(0, 1, saved_filename)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/train.py\", line 315, in train\n",
            "    valResult = doValidation(model, dataloaderVal, parallel = parallel, device = device)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/TrainUtil.py\", line 210, in doValidation\n",
            "    precision = nCorrect/nEst\n",
            "ZeroDivisionError: float division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "#!python3 -m transkun.train --nProcess 1 --datasetPath \"../OMAPS2\" --datasetMetaFile_train \"transkun/train.pickle\" --datasetMetaFile_val \"transkun/validation.pickle\" --batchSize 32 --max_lr 0.001 --nIter 100 --modelConf \"checkpoint/conf.json\" --augment \"../OMAPS2/weights/weights.pth\"\n",
        "\n",
        "# !python3 -m transkun.train --nProcess 1 \\\n",
        "#                            --datasetPath \"../OMAPS2\" \\\n",
        "#                            --datasetMetaFile_train \"transkun/train.pickle\" \\\n",
        "#                            --datasetMetaFile_val \"transkun/validation.pickle\" \\\n",
        "#                            --batchSize 4 \\\n",
        "#                            --max_lr 0.0001 \\\n",
        "#                            --nIter 90000 \\\n",
        "#                            --modelConf \"checkpoint/conf.json\" \\\n",
        "#                            --augment \\\n",
        "#                            \"../OMAPS2/weights/weights21.pth\"\n",
        "\n",
        "!python3 -m transkun.train --nProcess 1 \\\n",
        "                           --datasetPath \"../OMAPS2\" \\\n",
        "                           --datasetMetaFile_train \"transkun/train.pickle\" \\\n",
        "                           --datasetMetaFile_val \"transkun/validation.pickle\" \\\n",
        "                           --batchSize 4 \\\n",
        "                           --max_lr 0.0001 \\\n",
        "                           --nIter 9000000 \\\n",
        "                           --modelConf \"checkpoint/conf.json\" \\\n",
        "                           --augment \\\n",
        "                           \"../OMAPS2/weights/weights23.pth\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EcZeDXqFAJS",
        "outputId": "3e2c10ec-1688-4c42-fd81-10fb57a75d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-24 22:23:23.597901: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-24 22:23:23.651368: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-24 22:23:23.651444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-24 22:23:23.653187: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-24 22:23:23.661847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-24 22:23:24.778479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "initializing the model...\n",
            "{'f_min': 30, 'f_max': 8000, 'n_mels': 229, 'hopSize': 1024, 'windowSize': 4096, 'fs': 44100, 'nExtraWins': 5, 'preConvSpec': [{'outputSize': 48, 'hiddenSize': 48, 'kernelSize': 3, 'stride': [1, 2], 'dropoutProb': 0.0}, {'outputSize': 64, 'hiddenSize': 64, 'kernelSize': 3, 'stride': [1, 2], 'dropoutProb': 0.0}, {'outputSize': 92, 'hiddenSize': 92, 'kernelSize': 3, 'stride': [1, 2], 'dropoutProb': 0.0}, {'outputSize': 128, 'hiddenSize': 128, 'kernelSize': 3, 'stride': [1, 2], 'dropoutProb': 0.0}], 'ctxSize': 512, 'nLayersCtx': 2, 'rnnHiddenSize': 256, 'lengthScaling': True, 'postConv': True, 'disableUnitary': False, 'pitchEmbedSize': 256, 'scoreDropoutProb': 0.1, 'contextDropoutProb': 0.1, 'velocityDropoutProb': 0.1, 'refinedOFDropoutProb': 0.1}\n",
            "#0 loaded\n",
            "loading dataset....\n",
            "loading the annotation file...\n",
            "n: 147  totalDuration:  17182.9  elapsed: 0.33529090881347656\n",
            "creating index for notes in all pieces...\n",
            "elapsed: 0.03740549087524414\n",
            "loading the annotation file...\n",
            "n: 19  totalDuration:  2536.41  elapsed: 0.015623807907104492\n",
            "creating index for notes in all pieces...\n",
            "elapsed: 0.004469394683837891\n",
            "#0 loaded\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/mir_eval/transcription_velocity.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  slope, intercept = np.linalg.lstsq(\n",
            "/usr/local/lib/python3.10/dist-packages/torch_optimizer/adabelief.py:218: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  p.data.add_(-group['lr'], exp_avg)\n",
            "epoch:0 progress:0.000 step:0  loss:5896.8062 gradNorm:12.01 clipValue:40.00 time:14.61 \n",
            "nGT:366.0001 nEst:226169.0001 nCorrect:33.0001\n",
            "f1:0.00029134659077727806 precision:0.00014590903256153187 recall:0.09016418301525056\n",
            "f1Frame:0.032462936878486316 precisionFrame:0.01666556595494576 recallFrame:0.6231470995221\n",
            "mseVelocity:97.85286986601916 mseOF:0.1547832378788754\n",
            "epoch:0 progress:0.002 step:0  loss:5905.5884 gradNorm:12.10 clipValue:34.40 time:3.05 \n",
            "epoch:0 progress:0.004 step:0  loss:5907.4409 gradNorm:11.99 clipValue:28.84 time:2.38 \n",
            "epoch:0 progress:0.006 step:0  loss:5904.4058 gradNorm:11.95 clipValue:23.26 time:2.41 \n",
            "epoch:0 progress:0.008 step:0  loss:5899.3232 gradNorm:12.00 clipValue:17.68 time:2.38 \n",
            "epoch:0 progress:0.010 step:0  loss:5893.5684 gradNorm:11.97 clipValue:12.10 time:2.39 \n",
            "epoch:0 progress:0.012 step:0  loss:5896.1313 gradNorm:12.03 clipValue:12.08 time:2.39 \n",
            "size changed by sox!!\n",
            "epoch:0 progress:0.014 step:0  loss:5896.3735 gradNorm:12.05 clipValue:12.07 time:2.41 \n",
            "epoch:0 progress:0.016 step:0  loss:5895.1968 gradNorm:12.03 clipValue:12.07 time:2.39 \n",
            "epoch:0 progress:0.019 step:0  loss:5899.0693 gradNorm:12.02 clipValue:12.06 time:2.38 \n",
            "epoch:0 progress:0.021 step:0  loss:5906.2744 gradNorm:12.00 clipValue:12.05 time:2.38 \n",
            "epoch:0 progress:0.023 step:0  loss:5902.3584 gradNorm:11.97 clipValue:12.05 time:2.38 \n",
            "epoch:0 progress:0.025 step:0  loss:5885.6719 gradNorm:12.09 clipValue:12.04 time:2.38 \n",
            "epoch:0 progress:0.027 step:0  loss:5901.2100 gradNorm:12.03 clipValue:12.07 time:2.39 \n",
            "epoch:0 progress:0.029 step:0  loss:5893.0879 gradNorm:12.06 clipValue:12.06 time:2.37 \n",
            "epoch:0 progress:0.031 step:0  loss:5889.4600 gradNorm:12.08 clipValue:12.06 time:2.38 \n",
            "epoch:0 progress:0.033 step:0  loss:5897.1577 gradNorm:11.98 clipValue:12.07 time:2.39 \n",
            "epoch:0 progress:0.035 step:0  loss:5893.9722 gradNorm:12.08 clipValue:12.07 time:2.38 \n",
            "epoch:0 progress:0.037 step:0  loss:5904.4565 gradNorm:12.05 clipValue:12.08 time:2.38 \n",
            "epoch:0 progress:0.039 step:0  loss:5895.0303 gradNorm:12.04 clipValue:12.08 time:2.38 \n",
            "epoch:0 progress:0.041 step:0  loss:5896.9658 gradNorm:12.05 clipValue:12.08 time:2.39 \n",
            "epoch:0 progress:0.043 step:0  loss:5904.3232 gradNorm:12.01 clipValue:12.07 time:2.39 \n",
            "epoch:0 progress:0.045 step:0  loss:5910.3633 gradNorm:12.04 clipValue:12.07 time:2.38 \n",
            "epoch:0 progress:0.047 step:0  loss:5895.5776 gradNorm:12.03 clipValue:12.06 time:2.39 \n",
            "epoch:0 progress:0.049 step:0  loss:5893.9854 gradNorm:12.04 clipValue:12.06 time:2.39 \n",
            "epoch:0 progress:0.051 step:0  loss:5903.0156 gradNorm:11.98 clipValue:12.06 time:2.38 \n",
            "epoch:0 progress:0.053 step:0  loss:5905.3086 gradNorm:11.98 clipValue:12.05 time:2.38 \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/train.py\", line 397, in <module>\n",
            "    train(0, 1, saved_filename, args)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/train.py\", line 180, in train\n",
            "    logp = model.log_prob(audioSlices, notesBatch)\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/Model_ablation.py\", line 307, in log_prob\n",
            "    logZ = crfBatch.computeLogZ()\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/CRF/NeuralSemiCRFInterval.py\", line 585, in computeLogZ\n",
            "    return computeLogZFasterGrad(self.score, self.noiseScore)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 539, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level/transkun/CRF/NeuralSemiCRFInterval.py\", line 463, in forward\n",
            "    logz, grad, gradNoise = forward_backward(score, noiseScore)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Running and Evaluating the Audio Model**"
      ],
      "metadata": {
        "id": "azSoRILcd_41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Dissertation Code/Skipping-The-Frame-Level\")\n",
        "\n",
        "# Run the model ensuring the path to the new weights are included\n",
        "!python3 -m transkun.transcribe \"../OMAPS2/test/wav/01_01.wav\" \"output.mid\" --weight \"../OMAPS2/weights/weights20.pth\""
      ],
      "metadata": {
        "id": "Sfa5GZC2eAKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}